# AWS_SAA_Co3

☆ 중요포인트 이모티콘

리전은 데이터 센터의 집합

리전은 법률 준수, 지연 시간, 모든 리전이 모든 서비스를 가지고 있지 않음, 요금

AZ(가용영역)은 리전 내 여러 개 존재

각각의 AZ는 여분의 전원, 네트워킹 그리고 통신 기능을 갖춘 하나 또는 두 개의 개별적인 데이터 센터로 이루어짐

각각의 AZ들이 재난 발생에 대비해 서로 분리됨

이러한 AZ와 데이터센터들은 높은 대역폭의 초저지연 네트워킹으로 서로 연결되어 리전을 형성

[IAM(Identity and Access Management)]
- 글로벌 서비스
- 사용자 생성하고 그룹에 배치
- 계정 생성 시 루트 계정 생성
- 루트 계정은 계정(사용자) 생성시에만 사용
- 하나의 사용자는 조직 내의 한 사람에 해당
- 그룹에는 사용자만 배치 가능, 다른 그룹 포함 불가능
- 한 사용자가 다수의 그룹 가능
- 그룹을 형성하는 이유는 AWS 계정을 사용하도록 허용하기 위해
- 그리고 허용을 위해 권한 부여를 해야됨
- 이를 위해 사용자 또는 그룹에게 정책 또는 IAM 정책이라고 불리는 JSON 문서 지정 가능
- 비용 절감 및 보안을 위해 최소 권한 원칙 적용

[IAM 정책]
- inline 정책 : 그룹이 아닌 사용자에게 직접 정책 적용
- 정책구조 : Version, ID(Optional), Statement(내용)
- Statement 구성요소
1. Sid(문장 식별자, Optional)
2. Effect(접근 허용 or 거부)
3. Principal(특정 정책이 적용될 사용자/계정/혹은 역할로 구성)
4. Action(Effcect에 기반해 허용 및 거부되는 API 호출 목록)
5. Resource(적용될 Action의 리소스 목록)
6. Condition(Statement가 언제 적용될지 결정, Optional)

[IAM 비밀번호 정책]
1. 비밀번호 최소 길이 설정
2. 특정 유형의 글자 사용 요구
3. IAM사용자들의 비밀번호 변경 허용 및 금지
4. 일정기간이 지나면 새비밀번호 설정
5. 비밀번호의 재사용을 막음

[IAM MFA(Multi Factor Authentication)]
- 다요소 인증
- 필수적으로 사용하도록 권장
- 루트 계정은 구성 변경 및 리소스를 삭제할 수 있으므로 반드시 보호해야 함
- MFA = 비밀번호 + 보안 장치(MFA 장치)
- MFA 장치 종류
1. 가상 MFA 장치(ex. Google Authenticator, Authy 등)
2. U2F 보안키(Universal 2nd Factor, ex.Yubikey)
3. 하드웨어 Key Fob MFA Device(ex. Gemalto, SurePassID(AWS GovCloud 사용 시))

[AWS 접속 방법]
- AWS Management Console
1. Password
2. MFA
- CLI(Command Line Interface)
- SDK(Software Develope Kit)

[AWS Access 키]
- 터미널에서의 AWS 엑세스를 가능하게 함
- 관리 콘솔을 사용해서 생성 가능
- 사용자들이 자신들의 엑세스 키를 직접 관리
- 비밀번호와 동일한 취급
- Access Key ID ~= username
- Secret Access Key ~= password

[CLI]
- 명령줄 인터페이스
- 엑세스 키에 의해 보호됨
- AWS 서비스의 공용 API로 직접 액세스가 가능
- CLI를 통해 리소스를 관리하는 스크립트를 개발하여 일부 작업 자동화 가능
- AWS 관리 콘솔 대신 사용되기도 함

[SDK]
- AWS로부터 애플리케이션 코드 내에서 API를 호출하고자 할 때 사용되는 방식
- CLI와 동일한 엑세스 키에 의해 보호됨
- 특정 언어로 된 라이브러리의 집합
- AWS 서비스나 API에 프로그래밍을 위한 액세스가 가능하도록 해줌
- 터미널에서 사용하는 것이 아닌 코딩을 통해 애플리케이션 내에 심어두어야 함

[IAM ROLE]
- AWS Service에 권한 부여
- 사용자와 같지만 실제 사람이 사용하도록 만들어진 것이 아니고 AWS 서비스에 의해 사용되도록 만들어짐

[IAM 보안도구]
- IAM Credentials Report(account-level) : IAM 자격 증명 보고서
1. 계정에 있는 사용자와 다양한 자격 증명의 상태를 포함
- IAM Access Advisor(user-level)
1. 사용자에게 부여된 서비스의 권한과 해당 서비스에 마지막으로 엑세스한 시간이 보임
2. 최소 권한 원칙으로 설정할 때 매우 도움되는 정보

[EC2, Elastic Compute Cloud]
- 가장 인기있는 서비스
- 서비스형 InfraStructure
- EC2는 하나의 서비스가 아님
- 가상 머신을 EC2에서 임대할 수 있는데 이를 EC2 인스턴스라고 함
- 데이터를 가상 드라이브 또는 EBS 볼륨에 저장
- ELB(Elastic Load Balancer)로 로드 분산
- ASG(Auto Scaling Group)를 통해 서비스를 확장
- 핵심은 원하는 대로 가상 머신을 선택하여 AWS에서 빌릴 수 있음

[EC2 인스턴스 운영체제 선택]
- EC2 인스턴스의 운영 체제로 리눅스(가장 인기있음), 윈도우, 맥OS 선택 가능
- CPU 개수
- RAM(Random Access Memory)의 양- 저장용량
1. 네트워크를 통해 연결한 스토리지가 필요한 경우 EBS, EFS
2. 하드웨어에 연결할 경우 EC2 인스턴스 스토어가 됨
- EC2 인스턴스에 연결할 네트워크 종류 선택
1. 속도가 빠른 네트워크 카드인지
2. 어떤 종류의 공용 IP를 원하는지
- EC2 인스턴스의 방화벽 규칙 선택(보안 그룹)
- 인스턴스를 구성하기 위한 부트스트랩 스크립트(처음에 설정하는 EC2 사용자 데이터)

[EC2 User Data]
- EC2 사용자 데이터 스크립트를 사용하여 인스턴스를 부트스트래핑 가능
- 부트스트래핑은 머신이 작동될 때 명령을 시작하는 것, 즉 부팅 작업을 자동화
1. 업데이트
2. 소프트웨어 설치
3. 일반 파일 인터넷에서 다운로드 등
- 즉 스크립트는 처음 시작할 때 한 번만 실행되고 다시 실행되지 않음
- 사용자 데이터 스크립트에 작업을 더 추가할 수 록 부팅 시 인스턴스가 할 일 증가
- EC2 사용자 데이터 스크립트는 루트 계정에서 실행되므로 모든 명령문은 sudo로 해야됨

[AWS 인스턴스 명명 규칙]
- m5.2xlarge(=범용 인스턴스 5세대)
1. m : 인스턴스 클래스
2. 5 : 인스턴스 세대
3. 2xlarge : 인스턴스의 크기

[인스턴스 유형]
- General Purpose(범용 인스턴스)
1. 웹 서버, 코드 Repository 등 다양한 작업에 적합
2. 컴퓨팅, 메모리, 네트워킹 간의 균형도 잘맞음
3. ex) t2.micro

- Compute Optimized(컴퓨팅 최적화 인스턴스)
1. 컴퓨터 집약적인 작업에 최적화된 인스턴스(고성능 프로세서)
2. 고성능 CPU와 컴퓨팅이 요구되는 작업에 사용
ex 1. 일부 데이터를 일괄 처리에 사용 
ex 2. 미디어 트랜스코딩 작업 시
ex 3. 고성능 웹서버가 필요하거나 
ex 4. 고성능 컴퓨팅(HPC) 작업을 할때
ex 5. 머신 러닝이나 
ex 6. 전용 게임 서버가 있을 때 사용
3. 이름이 C로 시작

- Memory Optimized(메모리 최적화 인스턴스)
1. 메모리(RAM)에서 대규모 데이터 셋을 처리하는 유형의 작업에 빠른 성능을 제공
2. 고성능 관계형 or 비관계형 DB 사용
ex 1. Elastic Cash
ex 2. 분산 web scale cach 저장소
ex 3. BI(비즈니스 인텔리전스)에 최적화된 In-메모리 DB
ex 4. 대규모 비정형 데이터의 실시간 처리를 실행하는 애플리케이션에 사용
3. 이름이 R로 시작하지만 X1이나 Z1도 있음

- Storage Optimized(스토리지 최적화 인스턴스)
1. 로컬 스토리지에서 대규모의 데이터셋에 access할 때 적합
ex 1. OLTP(고주파 온라인 트랜잭션 프로세스) 시스템
ex 2. 관계형 DB or 비관계형 DB(NoSQL)에 사용
ex 3. 메모리 DB의 캐시(~= Redis)
ex 4. 데이터 웨어하우징 애플리케이션
ex 5. 분산 파일 시스템
2. 이름이 I, G 또는 H1으로 시작

[보안 그룹(방화벽)]
- EC2 인스턴스에 들어오고 나가는 트래픽을 제어
- 허용 규칙만 포함
- 출입이 허용된 것이 무엇인지 확인 가능
- IP주소를 참조하여 규칙 생성 가능
(컴퓨터의 위치나 다른 보안 그룹을 참조하는 것)
- 보안 그룹끼리 서로 참조 가능

[보안 그룹 예시]
- 컴퓨터에서 공공 인터넷을 사용하여 EC2 인스턴스를 엑세스하는 상황
- 보안 그룹은 외부에서 EC2 인스턴스로 들어오는 것(인바운드 트래픽)이 허용되면 아웃바운드 트래픽도 수행 가능
1. 보안 그룹은 EC2 인스턴스의 방화벽이며 포트로의 엑세스를 통제
2. 인증된 IP 주소의 범위를 확인하여 IPv4인지 Ipv6인지 확인
3. 외부에서 인스턴스로 들어오는 인바운드 네트워크 통제
4. 인스턴스에서 외부로 나가는 아웃바운드 네트워크도 통제

[보안그룹]
- 인바운드 규칙
1. 권한 없는 IP의 컴퓨터가 EC2 인스턴스에 엑세스하려고 하면 방화벽이 차단하여 타임아웃 발생
2. 모든 인바운드 트래픽 차단
- 아웃바운드 규칙
1. 모든 보안 그룹의 EC2 인스턴스는 기본적으로 모든 트래픽 허용
2. EC2 인스턴스가 웹사이트에 엑세스하고 연결을 시도하면 보안 그룹에서 허용
- 보안 그룹과  인스턴스는 M:N 관계
- 보안 그룹은 리전과 VPC 결합으로 통제
- 리전 전환 시 새 보안그룹 생성하거나 다른 VPC 생성해야 됨
- 보안그룹은 EC2 외부에 있어서 트래픽이 차단되면 EC2 인스턴스는 방화벽을 확인 불가능
- SSH 엑세스를 위해 하나의 별도 보안 그룹을 유지
- 타임아웃, 대기, 멈춤은 보안 그룹 문제
- 연결 거부 응답을 받았으면 보안그룹은 실행되었고 트래픽 통과했지만 애플리케이션에 문제가 생김
- 로드 밸런서를 사용한 보안그룹
1. 보안 그룹1이 보안 그룹2에 인바운드를 허용
2. 보안 그룹2에 연결된 어떤 인스턴스도 바로 통신이 가능
3. 이는 IP를 신경쓰지 않아도 되게 함

[SSH]
- 22 = SSH (Secure Shell) - log into a Linux instance
- 22번 포트로 Linux에서 EC2 인스턴스로 로그인하도록 함
- 21 = FTP (File Transfer Protocol) - upload file into a file share
- SSH를 사용해서 업로드하고 보안 파일 전송 프로토콜이 되기 때문에 SSH가 22번 포트를 사용
- 80 = HTTP - access unsecured websites
- 443 = HTTPS - access secured websites
- 3389 = RDP (Remote Desktop Protocal) - log into a Windows instance

[SSH]
- 클라우스에서 실행 시 유지 보수나 조치를 취하기 위해 서버 내부와 연결해야됨
- Linux 서버에서는 시큐어 셸인 SSH를 서버에 사용
- SSH는 명령줄 인터페이스 도구로 Mac, Linux, 윈도우10 이상에서 사용가능
- 윈도우 10미만은 putty사용
- EC2 Instance Connect는 터미널, putty가 아닌 웹 브라우저로 EC2 인스턴스에 연결

[EC2 인스턴스 구매 옵션]
- On-Demand 인스턴스
1. 단기적인 워크로드
2. 비용 예측가능
3. 초 단위 요금(가장 비쌈)
4. 단기적으로 중단없는 워크로드가 필요할 때 or 애플리케이션의 거동을 예측할 수 없을떄

- 예약 인스턴스
1. 기간은 1년 or 3년
2. 장기간의 워크로드가 target
3. 특정한 인스턴스 속성(인스턴스 타입, 리전, OS 등) 예약

- 전환형 예약 인스턴스
1. 시간이 지나면 인스턴스 타입, OS 등이 변경

- 절약 플랜
1. 기간은 1년 or 3년
2. 달러 단위로 특정한 사용량을 약정
3. 장기 워크로드를 위함
4. 특정한 인스턴스 패밀리, 리전으로 고정됨
5. 인스턴스 사이즈, OS, Tenancy 전환 가능

- Spot 인스턴스
1. 아주 짧은 워크로드를 위함
2. 아주 저렴함
3. 최대 가격 정의 후 스폿 가격이 최대 가격을 넘게 되면 인스턴스 손실
4. 신뢰성이 낮음
5. 고장에 대한 회복력이 있는 인스턴스라면 아주 유용
6. 아주 중요한 작업이나 데이터베이스는 적절하지 않음
ex) 배치, 데이터 분석, 이미지 처리, 모든 종류의 분산형 워크로드, 시작 및 종료 시간이 유연한 워크로드

- 전용 호스트
1. 물리적 서버 전체를 예약해서 인스턴스 배치를 제어할 수 있음
2. 온디맨드 or 1년 예약 or 3년 예약
3. 물리적 서버를 예약하므로 가장 비싼 옵션
4. 물리적 서버 자체에 대한 접근성을 갖고 낮은 수준의 하드웨어에 대한 가시성을 제공
ex) 법규 준수 요건이 있거나 소켓, 코어 VM 소프트웨어 라이센스를 기준으로 청구되는 기존의 서버에 연결된 SW 라이센스

- 전용 인스턴스
1. 다른 고객이 여러분의 하드웨어를 공유하지 않는다는 의미
2. 고객의 전용 하드웨어에서 실행되는 인스턴스
3. 고객은 같은 계정에서 다른 인스턴스와 함께 하드웨어를 공유할 수 있고 인스턴스 배치에 대한 통제권이 없음
4. 자신만의 인스턴스, 자신만의 하드웨어를 가짐

- 용량 예약
1. 원하는 기간동안 특정한 AZ에 온디맨드 인스턴스를 예약할 수 있음
2. 기간 약정 없이 언제라도 용량 예약 및 취소 가능
3. 청구 할인을 위해 지역별 예약 인스턴스와 결합하거나 절약 플랜과 결합
4. 인스턴스 실행과 무관하게 온디맨드 요금 부과
5. 특정한 AZ에 있어야 하는 단기적이고 중단 없는 워크로드에 아주 적합

[EC2 스팟 인스턴스]
- 지불할 수 있는 최대 스팟 가격 정의
- 인스턴스의 스팟 가격이 우리가 지불하고자 하는 최대 가격보다 낮다면 해당 인스턴스 유지
- 시간당 스팟은 offer와 용량에 따라 달라짐
- 현재 스팟 가격이 정의된 최대 가격을 초과하면 두 가지 선택 가능(2분의 유예 기간 주어짐)
1. 하던 작업을 모두 중지하고 인스턴스를 중지 => 스팟 가격이 최대 가격 아래로 다시 내려가면 인스턴스 재시작하고 중단했던 곳부터 재개
2. EC2 인스턴스 종료 => 작업을 다시 시작할 때 새로운 EC2 인스턴스로 시작
- AWS가 스팟 인스턴스 회수하는 것을 원하지 않는다면 스팟 블록 사용가능
1. 지정된 기간동안 스팟 인스턴스를 차단
2. 1~6시간 가능
3. 그동안 중단 없이 해당 블록을 사용할 수 있다고 규정
4. 아주 드물게 인스턴스가 회수되는 경우가 있음
5. 스팟 가격은 AZ에 따라 달라짐

[스팟 인스턴스 종료하는법]
- 스팟 요청에서는 원하는 인스턴스 수, 최대 가격 및 시작 사양 등을 정의
- 언제부터 언제까지 유효한지, 무한대도 가능
- 요청 유형
1. 스팟 인스턴스 일회성 요청
a. 스팟 요청이 완료되는 즉시 인스턴스가 시작
b. 스팟 요청이 사라짐
2. 영구 인스턴스 요청
a. 스팟 요청이 유효한 기간 동안은 이 인스턴스 수도 유효
b. 인스턴스가 어떤 이유로든 중지되거나 스팟 가격을 기준으로 중단되는 경우 스팟 요청이 다시 실행되고 유효성이 확인되면 스팟인스턴스가 자동으로 다시 시작
- 스팟 요청을 취소하려면 Open, Active, Disabled 상태여야 함(failed, canceled 상태에서는 안됨)
- 스팟 요청을 취소하고 싶을 때는 이전에 시작한 인스턴스를 종료하는 것이 아님(인스턴스를 종료하는 것은 AWS가 아닌 고객이 할일이므로)
- 스팟 인스턴스를 완전히 종료하기 위해 스팟 요청을 취소하고 그 다음 관련 스팟 인스턴스를 종료해야 함(다시 시작안되도록)

[스팟 Fleets]
- 비용을 절감하는 궁극적인 방법
- 스팟 인스턴스 세트를 정의하는 방법(+(Optional) 온디맨드 인스턴스)
- 스팟 플릿은 정의한 가격 제한으로 목표 용량을 충족시키기 위해 최선을 다함
1. 가능한 launch pools : 다양한 인스턴스 타입, OS, AZ
2. 스팟 플릿이 가장 적합한 launch pool을 선택
- 스팟 플릿이 예산에 도달하거나 원하는 용량에 도달하면 launch 인스턴스를 중지
- 따라서 스팟 플릿에 스팟 인스턴스를 할당하는 전략을 정의해야 함
1. 최저 가격
a. 스팟 플릿은 가장 낮은 가격인 pool에서 인스턴스를 시작하기 때문에 비용이 최적화
b. 워크로드가 매우 짧은 경우 좋은 옵션
2. 다양한 방법으로 스팟 인스턴스 실행
a. 스팟 인스턴스는 모든 pool에 분산
b. 가용성과 긴 워크로드에 적합
c. 한 pool이 사라져도 다른 pool은 여전히 활성화
3. 용량 최적화
a. 원하는 인스턴스 수에 맞는 최적의 용량을 가진 pool을 갖게 됨
4. 가격 용량 최적화
a. 먼저 사용 가능한 용량이 가장 큰 pool을 선택하고 그 중 가격이 가장 낮은 pool을 선택하는 전략
b. 대부분의 워크로드에 가장 적합한 선택
- 스팟 플릿을 사용하면 여러 개의 Launch pool과 여러 인스턴스 타입을 정의할 수 있어 전력만 신경쓰면 됨
- 스팟 플릿에서 최저가 할일 또는 최저가 전략을 사용하면 스팟 플릿이 자동으로 가장 낮은 가격의 스팟 인스턴스를 요청
- 스팟 플릿은 스팟 인스턴스를 기반으로 추가 비용 절감

[스팟 인스턴스 vs 스팟 플릿]
- 간단한 스팟 인스턴스를 요청하는 경우는 원하는 인스턴스 유형과 AZ를 정확히 알고 있는 경우
- 스팟 플릿을 요청하는 경우는 조건에 만족하는 모든 인스턴스 유형과 모든 AZ를 선택

[Private vs Public vs Elastic IP]
- IPv4
1. 가장 대중적인 IP
2. 네 개의 숫자가 세 개의 점으로 분리된 형태
3. [0-255].[0-255].[0-255].[0-255]
ex) 1.160.10.240
- IPv6
1. 조금 덜 대중적임
2. 정말 길고 독특한 숫자 기호와 문자로 이루어짐
ex) 1900:4545:3:200:f8ff:fe21:67cf
- Public IP
1. 인터넷 전역에 엑세스 가능
2. Public IP를 가진 서버들끼리 IP를 사용하여 서로 통신 가능
3. 기기가 인터넷상에서 식별될 수 있음을 의미(ex. WWW)
4. 공용IP가 전체 웹에서 유일한 것이어야 함
5. IP의 지리적 위치를 쉽게 찾을 수 있음

- Private IP
1. Private 네트워크 내에서만 엑세스 가능
2. Private 네트워크에는 사설 IP 범위가 있는데 기본적으로 Private 네트워크 내의 모든 컴퓨터가 사설 IP를 사용하여 서로 통신할 수 있음
3. public 게이트웨이인 인터넷 게이트웨이(+NAT 장치)를 이용하면 다른 서버에 엑세스 가능
4. 기기가 Private 네트워크 안에서만 식별 가능
5. IP가 Private 네트워크 안에서만 유일하면 됨
6. 지정된 범위의 IP만 사설 IP로 사용 가능

- Elastic IP
1. EC2 인스턴스를 시작하고 중지할 때 공용IP를 바꿀 수 있음
2. 인스턴스에 고정된 IP를 사용하면 Elastic IP가 필요
3. Elastic IP는 Public IP
4. 삭제되지 않는 한 계속 가지고 있음
5. 한 번에 한 인스턴스에만 attach 가능
6. 계정당 탄력적 IP를 5개만 사용 가능(AWS에 개수 증가를 요청할 수 있지만 드문 케이스)
6-1. 위로 인해 IP 주소가 탄력적이면 한 인스턴스에서 다른 인스턴스로 빠르게 이동함으로써 인스턴스 또는 소프트웨어의 오류를 마스킹할 때 사용할 수 있는 경우가 드뭄
7. 매우 좋지 않은 구조적 결정으로 탄력적 IP는 사용하지 않는 것이 좋음
8. 대신 임의의 공용 IP를 써서 DNS 이름을 할당하는 것이 좋음
9. DNS는 Route53에서 살펴볼 예정으로 훨씬 더 많은 제어가 가능하고 확장 가능성이 큼
10. 로드 밸런서를 사용해서 공용IP를 전혀 사용하지 않을 수 도 있음
11. 9와 10이 AWS에서 취할 수 있는 최상의 패턴

- EC2 기기에 SSH를 할 땐 VPN을 쓰지 않는 이상 같은 네트워크가 아니므로 Private IP 사용 불가능
- 기기를 멈췄다가 다시 시작하면 공용IP가 바뀔 수 있음

[EC2 배치 그룹]
- EC2 인스턴스가 AWS 인프라에 배치되는 방식을 제어할 때 사용
- AWS의 하드웨어와 직접적인 상호 작용을 하지는 않지만 EC2 인스턴스가 각각 어떻게 배치되기를 원하는지 AWS에 알려줌
- 배치 그룹을 만들 때 세 가지 전략 사용 가능

1. Cluster - 클러스터 배치 그룹
a) 단일 AZ 내에서 지연 시간이 짧은 하드웨어 설정으로 인스턴스를 그룹화 할 클러스터 배치 그룹
b) 모든 인스턴스가 동일한 Rack에 있음 즉 동일한 하드웨어와 동일한 AZ에 있다는 거임
c) 지연시간이 매우 짧은 10GB속도의 높은 성능 제공
d) Rack에서 Fail이 발생 즉 하드웨어에 Fail이 발생하면 모든 EC2 인스턴스가 동시에 Fail하므로 위험도 높음
e) 극히 짧은 지연 시간과 높은 네트워크 처리량을 필요로 하는 애플리케이션에 적용 가능(ex. 빅데이터)

2. Spread - 분산 배치 그룹
a) 모든 EC2 인스턴스를 다른 하드웨어에 분산하여 Fail 위험 최소화
b) 배치 그룹의 AZ 당 7개의 EC2 인스턴스만 가질 수 있다는 제한 사항있음
c) 위와 같이 배치 규모에 제한이 있어 크기는 적당하지만 너무 크지는 않은 애플리케이션에서만 쓸 수 있음
d) 가용성을 극대화하고 위험을 줄여야하는 크리티컬한 애플리케이션이 있는 경우 분산 배치 그룹 사용

3. Partition - 분할 배치 그룹(매우 유용함)
a) 분산 배치 그룹과 비슷하게 인스턴스를 분산하려는 것
b) 여러 파티션에 인스턴스가 분할되어 있고 이 파티션은 AZ내의 다양한 하드웨어 Rack 세트에 의존
c) 가용 영역 당 최대 7개의 파티션이 있을 수 있음(각 파티션은 AWS Rack을 의미)
d) 파티션이 많으면 인스턴스가 여러 하드웨어 Rack에 분산되어 서로 Rack Fail로부터 안전
e) 파티션은 동일한 리전의 여러 AZ영역에 걸쳐 있을 수 있음
f) 설정으로 최대 수백 개 EC2 인스턴스를 얻을 수 있음
g) EC2 인스턴스가 어떤 파티션에 있는지 알기 위해 메타데이터 서비스를 사용하여 이 정보에 엑세스하는 옵션이 있음
h) 파티션들 전반에 걸쳐 데이터와 서버를 퍼트려 두도록 파티션 인식 가능한 애플리케이션에 사용
i)그룹 당 수백 개의 EC2 인스턴스를 통해 확장가능하고 이를 통해 하둡, Cassandra, Kafka 같이 파티션을 인식하는 빅데이터 애플리케이션에 사용

[Elastic Network Interface(ENI)]
- VPC의 논리적 구성 요소이며 가상 네트워크 카드를 나타냄
- EC2 인스턴스가 네트워크에 엑세스할 수 있게 해줌
- ENI는 EC2 인스턴스 외부에서도 사용됨
- 주요 사설 IPv4와 하나 이상의 보조 IPv4를 가질 수 있음 즉 EC2에 보조 ENI를 얼마든지 추가 가능
- 각 ENI는 사설 IPv4당 탄력적 IPv4를 갖거나 하나의 공용 IPv4를 가질 수 있으므로 사설 및 공용 IP가 한 개씩 제공됨
- ENI에 하나 이상의 보안 그룹을 연결할 수 있음
- Mac 주소 및 기타 항목을 연결할 수 있음
- EC2 인스턴스와 독립적으로 ENI를 생성하고 즉시 연결하거나 장애 조치를 위해 EC2 인스턴스에서 이동시킬 수 있음
- ENI는 특정 AZ에 바인딩됨 즉 특정 AZ에서 ENI를 생성하면 해당 AZ에만 바인딩 가능
- 첫 번째 EC2 인스턴에서 두 번째 EC2 인스턴스로 ENI를 옮겨서 사설 IP를 이동시킬 수 있음
- 그러면 사설 IP가 첫 번쨰 문제 인스턴스에서 두 번째 EC2 인스턴스로 연결됨 이는 장애 조치에 매우 유용

[EC2 절전모드(Hibernate)]
- 인스턴스를 중지하면 EBS 디스크 데이터는 다시 시작할 때까지 그대로 유지
- 인스턴스를 종료한다면 root 볼륨(EBS)이 삭제되게 했다면 인스턴스도 삭제
- 그렇게 설정하지 않은 다른 볼륨은 인스턴스가 종료되더라도 그대로 남음
- 인스턴스를 다시 시작하면 운영체제가 먼저 부팅되기 시작하고 EC2 사용자 데이터 스크립트도 실행됨
- 그 뒤 운영체제 부팅이 완료되고 애플리케이션도 실행되며 캐시도 구성되기 시작하므로 과정이 끝날 때까지 시간이 다소 걸림
- 인스턴스가 절전 모드가 되면 RAM에 있던 인 메모리 상태는 그대로 보존되어 인스턴스 부팅이 더 빨라짐
- 운영체제를 완전히 중지하거나 다시 시작하지 않고 그대로 멈췄기때문임
- 절전모드가 되고 백그라운드에서 RAM에 기록되었던 인 메모리 상태는 루트 경로의 EBS 볼륨에 기록되기 때문에 루드 EBS 볼륨을 암호화해야 함
- 볼륨 용량도 RAM을 저장하기에 충분해야함
- 인스턴스를 다시 실행하면 디스크에서 RAM을 불러와 EC2 인스턴스 메모리로 가져옴
- EC2 인스턴스를 중지한 적 없는 것처럼 됨
- 지원하는 제품군이 많고 인스턴스 RAM 크기는 최대 150GB
- 베어 메탈 인스턴스에 적용할 수 없고 Linux, Windows 등의 여러 운영 체제에서 사용할 수 있음
- 루트 볼륨, 즉 EBS에만 저장이 가능하며 암호화가 필요하고 덤프된 RAM을 포함할만큼 충분한 용량이 있어야 함
- 온디맨드, 예약, 스팟과 같은 모든 종류의 인스턴스에 사용 가능
- 절전 모드는 최대 60일까지 사용 가능

[EC2 Hibernate 사용 사례]
- 오래 실행되는 프로세스를 갖고 있고 중지하지 않을 때
- RAM 상태를 저장하고 싶을 때
- 빠르게 재부팅을 하고 싶을 때
- 서비스 초기화가 시간을 많이 잡아먹어 서비스가 중단없이 인스턴스를 절전 모드로 전환하고 싶을 때

[Elastic Block Store(EBS)]
- 인스턴스가 실행 중인 동안 연결가능한 네트워크 드라이브(물리적 드라이브가 아님)
- EBS 볼륨을 사용하면 인스턴스가 종료된 후에도 데이터를 지속할 수 있음
- 인스턴스를 재생성하고 이전 EBS 볼륨을 마운트하면 데이터를 다시 받을 수 있음
- CCP 레벨의 EBS 볼륨은 한 번에 하나의 인스턴스에만 마운트 가능 / 일부 EBS는 다중 연결(인스턴스 하나에 여러 개 EBS 볼륨 연결은 가능)
- EBS 볼륨을 생성할 때는 특정 AZ 영역에서만 사용 가능
- us-east-1a에서 생성된 경우 us-east-1b에는 연결 불가능
- 스냅샷을 이용하면 다른 AZ으로도 볼륨을 옮길 수 있음
- EBS 볼륨은 네트워크 UBS 스틱과 유사함
- UBS 스틱처럼 한 컴퓨터에서 꺼내서 다른 컴퓨터에 꽂는 장치는 맞지만 실제 물리적 연결이 아닌 네트워크를 통해 연결
- 무료 등급으로는 매달 30GB의 EBS 스토리지를 범용 SSD or 마그네틱 유형으로 제공
- 인스턴스와 EBS 볼륨이 서로 통신을 하기 위해 네트워크를 필요
- 네트워크가 사용되기 때문에 컴퓨터가 다른 서버에 도달할 때 지연이 생길 수 있음
- EBS 볼륨은 네트워크 드라이브이므로 EC2 인스턴스에서 분리될 수 있고 매우 빠르게 다른 인스턴스로 연결 가능
- 이로 인해 대체 작동 등의 경우에 매우 유용
- 볼륨이기 때문에 용량을 미리 결정해야 하므로 원하는 양의 GB 및 IOPS, 즉 단위 초당 전송 수를 미리 지정해야함(향후에 용량을 늘릴 수 있음)
- 해당 프로비전 용량에 따라 요금이 청구됨

[인스턴스 종료 시 EBS 삭제]
- EC2 인스턴스를 통해 EBS 볼륨을 생성하는 경우 종료 시 삭제 속성이 있음
- 기본 설정으로는 루트 볼륨에 체크되어 있고 새로운 EBS 볼륨에는 체크되어있지 않음
- 인스턴스가 종료될 때 루트 볼륨을 유지하고자 하는 경우, 데이터를 저장하고자 하는 등의 경우에는 루트 볼륨의 종료 시 삭제 속성을 비활성화하면 됨

[EBS 스냅샷]
- EBS 볼륨의 특정 시점에 대한 백업
- EBS 인스턴스에서 EBS 볼륨을 분리할 필요는 없지만 권장 사항임
- EBS 스냅샷은 다른 AZ나 다른 리전에도 복사할 수 있음

[EBS 스냅샷 기능]
- EBS 스냅샷 아카이브
1. 최대 75%까지 저렴한 아카이브 티어로 스냅샷을 옮길 수 있는 기능
2. 아카이브를 복원하는 데 24시간에서 최대 72시간이 걸림
3. 즉시 복원되지 않음

- EBS 스냅샷 휴지통
1. EBS 스냅샷을 삭제하는 경우 영구 삭제하는 대신에 휴지통에 넣을 수 있음
2. 실수로 삭제하는 경우에 휴지통에서 복원 가능
3. 휴지통에 보관되는 기간은 1일에서 1년 사이로 설정 가능

- 빠른 스냅샷 복원(FSR)
1. 스냅샷을 완전 초기화해 첫 사용에서의 지연 시간을 없애는 기능
2. 스냅샷이 아주 크고 EBS 볼륨 또는 EC2 인스턴스를 빠르게 초기화해야 할 때 유용
3. 비용이 많이 듬

[Amazon Machine Image(AMI)]
- EC2 인스턴스를 통해 만든 이미지
- AMI로 AWS를 구축할 수 있고 원하는 대로 변경 가능
- AMI에다 원하는 소프트웨어 또는 설정 파일을 추가하거나 별도의 운영 체제를 설치할 수 도 있고 모니터링 툴을 추가할 수 있음
- AMI를 따로 구성하면 부팅 및 설정에 드는 시간을 줄일 수 있음
- EC2 인스턴스에 설치하고자 하는 모든 SW를 AMI가 미리 패키징해줌
- AMI를 특정 리전에 구축한 다음 다른 지역으로 복사해서 AWS의 글로벌 인프라를 활용할 수 있음
- AWS에서 제공하는 AMI, 직접 만든 AMI 등 여러 종류가 있음
- 직접 만든거는 당연하게도 직접 유지 및 관리해야됨
- 다른 사람이 구축한 이미지를 AWS 마켓플레이스 AMI에서 구매하여 EC2 인스턴스를 실행할 수 있음

[AMI Process]
- 먼저 EC2 인스턴스를 원하는 대로 설정해줌
- 그 후 인스턴스를 중지해 데이터 무결성 확보
- 이 인스턴스를 바탕으로 AMI 구축
- 이 과정에서 EBS 스냅샷 생성
- 이 후 다른 AMI에서 인스턴스를 실행할 수 있음

[ECS Instance Store]
- 물리적 서버에 연결된 하드웨어 드라이브
- EC2 인스턴스는 가상 머신이지만 실제로는 하드웨어 서버에 연결되어 있어야함
- 이와 같은 서버에는 해당 서버에 물리적으로 연결된 디스크 공간을 가짐
- EC2 인스턴스 스토어는 I/O 성능 향상을 위해 활용할 수 있음
- 훌륭한 처리량을 갖추고 있어서 월등한 디스크 성능이 필요할 때 EC2 인스턴스 스토어를 확보할 필요가 있음
- EC2 인스턴스 스토어를 중지 또는 종료하면 해당 Storage 또한 손실됨(임시 스토리지)
- 그러므로 EC2 인스턴스 스토어는 장기적으로 데이터를 보관할만한 장소가 될 수 없고 장기 스토리지로는 EBS가 적합
- 버퍼, 캐시, 스크래치 데이터 또는 임시 콘텐츠를 사용하는 경우에 활용
- EC2 인스턴스의 기본 서버에 장애가 발생할 시 해당 EC2 인스턴스가 연결된 하드웨어에도 장애가 발생하므로 데이터 손실에 대한 위험 존재
- 따라서 EC2 인스턴스 스토어를 사용할 때에는 데이터를 백업해 두거나 복제해야함

[EBS 유형]
- gp2/gp3(SDD)
1. 범용 SSD 볼륨으로 다양한 워크로드에 대해 가격과 성능의 절충안
2. 부팅 볼륨 사용 가능(루트 OS가 실행될 위치에 해당)
- io1/io2(SDD)
1. 최고 성능을 자랑하는 SSD 볼륨으로 미션 크리티컬이자 지연 시간이 낮고 대용량 워크로드에 사용
2. 부팅 볼륨 사용 가능(루트 OS가 실행될 위치에 해당)
- st1(HDD)
1. 저비용의 HDD 볼륨으로 잦은 접근과 처리량이 많은 워크로드에 사용
- sc1(HDD)
1. 가장 비용이 적게 드는 HDD 볼륨으로 접근 빈도가 낮은 워크로드를 위해 설계됨
- EBS 볼륨은 크기, 처리량, IOPS(초당 I/O 작업 수)로 정의

[gp2 VS gp3]
- 범용 gp2와 IOPS 프로비저닝이 가장 중요한 내용으로 시험에 출제됨
- gp2
1. 짧은 지연 시간, 효율적인 비용의 스토리지
2. 시스템 부팅 볼륨에서 가상 데스크톱, 개발, 테스트 환경에서 사용 가능
3. 크기는 1GB ~ 16TB까지 다양함
4. 최대 3,000 IOPS의 1 볼륨과 IOPS가 독립적인 관계가 아닌 링크되어 있어 용량의 GB 수를 3배로 늘릴 때 IOPS 세 배 더 증가하며 최대 16,000 IOPS까지 늘릴 수 있음
- gp3
1. 최신 세대의 볼륨
2. 기본 성능 3,000IOPS와 초당 125MB의 처리량 제공
3. 16,000IOPS와 초당 1,000MB까지 독립적으로 증가 가능

[프로비저닝 IOPS(PIOPS) SSD]
- IOPS 성능을 유지할 필요가 있는 주요 비즈니스 애플리케이션이나 16,000 IOPS 이상을 요하는 애플리케이션에 적합
- 스토리지로 이용하는 경우 데이터베이스 워크로드에 적합
- 이 경우는 스토리지 성능과 일관성에 아주 민감한데 gp2/gp3에서 io1/io2 볼륨으로 바꾸는 것이 해답이 될 수 있음
- io1/io2 중 최신 세대를 선택하는 것이 좋음

[io1 VS io2]
- 4GB ~ 16TB
- Nitro EC2 인스턴스에서는 최대 64,000 IOPS까지 지원
- Nitro EC2 인스턴스가 아닌 경우 최대 32,000 IOPS까지 지원
- io1/io2를 이용하면 gp3 볼륨처럼 프로비저닝된 IOPS를 스토리지 크기와 독자적으로 증가 가능
- io2 장점
1. io1와 동일한 비용으로 내구성과 기가 당 IOPS 수가 더 높음
- io2 Block Express
1. 4GB ~ 64TB
2. 좀 더 고성능 유형의 볼륨
3. 지연 시간이 ms 미만
4. IOPS 대 GB 비율이 1,000:1 일때 최대 256,000 IOPS

[st1 vs sc1]
- 최대 16TB까지 확장가능
- st1
1. 처리량 최적화 HDD
2. 빅 데이터나 데이터 웨어하우징 로그 처리에 적합
3. 최대 처리량은 초당 500MB 그리고 최대 IOPS는 500
- sc1(Cold HDD)
1. 아카이브 데이터용으로 접근 빈도가 낮은 데이터에 적합
2. 최저 비용으로 데이터를 저장할 때 사용
3. 최대 처리량은 초당 250MB 그리고 최대 IOPS도 250

[시험 출제 요건]
- 대략적인 모든 볼륨의 차이
- 범용 SSD VS 프로비저닝 IOPS SSD의 차이
- 데이터 베이스가 필요할 떄와 대용량, 저비용을 요할 때
- st1을 사용하는 경우 그 차이
- 32,000 IOPS 이상을 요할 때는 io1 또는 io2 볼륨의 EC2 Nitro

[EBS Multi Attach]
- 하나의 EBS 볼륨을 같은 AZ에 있는 여러 EC2 인스턴스에 연결할 수 있게 하는 기능
- io1/io2 제품군만 사용 가능
- 각 인스턴스는 고성능 볼륨에 대한 읽기 및 쓰기 권한을 전부 가짐(동시에 읽고 쓰기 가능)
- 해당 AZ 내에서만 사용 가능(한 AZ에서 다른 AZ로 EBS 볼륨 연결 불가능)
- 한 번에 16개의 EC2 인스턴스만 같은 볼륨에 연결 가능(중요!!!)
- 반드시 클러스터 인식 파일 시스템을 사용해야 EBS Multi Attach 이용 가능(XFS, EX4와 같은 파일시스템과 다름)

[EBS Multi Attach 예시]
- Teradata처럼 클러스터링 된 Linux 애플리케이션에서 사용
- 애플리케이션이 동시 쓰기 작업을 관리할 때 사용

[EBS 암호화]
- EBS 볼륨 생성 즉시 암호화 발생
1. 저장 데이터가 볼륨 내부에 암호화
2. 인스턴스와 볼륨 간의 전송 데이터 암호화
3. 스냅샷 뿐만 아니라 스냅샷으로 생성된 볼륨 역시 모두 암호화
- 이러한 암호화는 동시다발적으로 일어남
- 이때 암호화 및 복호화 메커니즘은 보이지 않게 자동으로 처리됨
- 지연 시간에는 거의 영향 없음
- KMS에서 암호화 키를 생성해 AES-256 암호화 표준을 가짐
- 스냅샷을 복사해 암호화를 푼 걸 다시 암호화 활성화를 함

[EBS 암호화 과정]
- 볼륨의 EBS 스냅샷 생성
- 복사 기능을 통해 EBS 스냅샷을 암호화
- 스냅샷을 이용해 새 EBS 볼륨을 생성하면 해당 볼륨도 암호화
- 그 후 암호화된 볼륨을 인스턴스 원본에 연결

[EFS(Elastic File System)]
- EFS는 관리형 NFS(네트워크 파일 시스템)
- NFS이므로 많은 EC2 인스턴스에 마운트 가능
- 서로 다른 AZ영역의 EC2 인스턴스에서도 EFS 기능 가능
- 가용성의 높고 확장성이 뛰어나며 비쌈(GP2 EBS 볼륨의 약 3배)
- 사용량에 따라 비용을 지불하므로 미리 용량을 프로비저닝할 필요 없음

- EFS의 사용 사례는 콘텐츠 관리, 웹 serving, 데이터 공유, Wordpress
- 내부적으로 NFSv4.1 프로토콜을 사용
- EFS에 대한 엑세스를 제어하려면 보안그룹을 설정해야함
- 윈도우가 아닌 Linux 기반 AMI와만 호환됨
- KMS를 사용해서 EFS 드라이브에서 미사용 암호화를 활성화 가능
- Linux 표준 파일 시스템으로 Posix 시스템을 사용하며 표준 파일 API가 있음
- 용량을 미리 설정할 필요 없이 자동으로 확정되며 EFS에서 사용하는 데이터 GB 사용량에 따라 비용을 지불

[EFS의 성능]
- EFS 스케일
1. 동시 NFS 클라이언트 수천 개와 10GB 이상의 처리량을 확보 가능
2. PB 규모의 NFS으로 자동 확장 가능

- NFS 생성 시 성능 모드 설정
1. 범용 : default 값이며 지연 시간에 민감한 사용 사례(웹서버나 CMS)에 사용
2. Max I/O : 지연 시간이 더 긴 NFS이지만 처리량이 높고 병렬성이 높으므로 빅 데이터 애플리케이션이나 미디어 처리가 필요한 경우 유용

- Throughput Mode(처리량 모드)
1. Bursting : 1TB = 초당 50MB ~ 100MB
2. 프로비저닝 : 스토리지 크기에 관계없이 처리량을 설정(ex. 1TB 스토리지 1GiB를 처리)
3. Elastic : 워크로드에 따라 처리량을 자동으로 조절(ex. 읽기는 초당 최대 3GiB, 쓰기는 초당 1GiB까지 가능), 워크로드를 예측하기 어려울 때 유용

[EFS의 스토리지 클래스]
- Storage Tiers
1. 며칠 후 파일을 다른 계층으로 옮길 수 있는 기능
2. EFS Standard 계층은 자주 엑세스하는 파일을 위한 계층이고 자주 엑세스하지 않는 계층은 EFS IA인데, 이 계층에서 파일을 검색할 경우 비용이 발생
3. 하지만 파일을 EFS-IA에 저장하면 비용이 감소
4. EFS_IA를 사용하려면 수명 주기 정책을 사용해해야 함(만약 특정 파일 60일동안 사용하지 않았다면 자동으로 표준 계층에서 EFS_IA 계층으로 이동)

- 가용성 & 내구성
1. 다중 AZ로 EFS를 설정(AZ 하나가 다운되어도 EFS에 영향 미치지 않음)
2. 개발용으로 One Zone EFS을 사용 가능
3. 개발에는 좋지만 하나의 AZ에만 있고 백업은 기본적으로 활성화되도록 설정되어 있으며 엑세스 빈도가 낮은 스토리지 계층과 호환되지 않음
4. 따라서 EFS One Zone IA라고 불리며, 이를 사용하면 굉장히 할인이 많이 됨

- 시험에는 언제 EFS를 사용해야 하는지, NFS에 어떤 옵션을 설정해야 하는지 나옴

[High Availability VS Scalablility]
[확장성(Scalablility)]
- 애플리케이션 시스템이 조정을 통해 더 많은 양을 처리할 수 있다는 의미

- 수직 확장성
1. 인스턴스의 크기를 확장
2. 예시 : t2.micro에서 t2.large로 확장
3. 데이터베이스와 같이 분산되지 않은 시스템에서 흔히 사용
4. RDS나 ElastiCache 등의 데이터베이스에서 쉽게 찾아볼 수 있음
5. 이 서비스들은 하위 인스턴스의 유형을 업그레이드해 수직적으로 확장할 수 있는 시스템들
6. 하드웨어 제한으로 인해 확장할 수 있는 한계가 있음
7. 확장(스케일 업), 축소(스케일 다운)
8. 수직 확장을 통해 매우 작은 인스턴스부터 대규모로 확장 가능

- 수평 확장성
1. 애플리케이션에서 인스턴스나 시스템의 수를 늘리는 방법
2. 수평 확장을 했다는 건 분배 시스템이 있다는 것을 의미
3. 증가(스케일 아웃), 감소(스케인 인)
4. 다른 스케일링 그룹이나 로드 밸런서에도 사용

[고가용성(High Availability)]
- 애플리케이션 or 시스템을 적어도 둘 이상의 AWS의 AZ나 데이터 센터에서 가동 중이라는걸 의미함
- 고가용성의 목표는 데이터 센터에서의 고장에서 생존하는 것으로 센터 하나가 멈춰도 계속 작동하게끔 하는 것
- 고가용성도 RDS 다중 AZ를 갖추고 있다면 수동적일 수 있음(수동형 고가용성)
- 수평 확장하는 경우에는 활성형이 될수도 있음
- 동일 애플리케이션의 동일 인스턴스를 다수의 AZ에 걸쳐 실행하는 경우를 의미
- 다중 AZ가 활성화된 자동 스케일러 그룹이나 로드 밸런서에서도 사용  

[Load Balancing]
- 로드 밸런서는 서버 or 서버set으로 트래픽을 백엔드나 다운스트림 EC2 인스턴스 or 서버들로 전달하는 역할
- 부하를 다수의 다운스트림 인스턴스로 분산하기 위함
- 애플리케이션에 단일 엑세스 지점(DNS)을 노출
- 다운스트림 인스턴스의 장애를 원활히 처리 가능
- 로드 밸런서가 상태 확인 메커니즘으로 어떤 인스턴스로 트래픽을 보낼 수 없는지 확인해줌
- SSL 종료도 할 수 있어서 웹 사이트에 암호화된 HTTPS 트래픽을 가질 수 있음
- 쿠키로 고착도(stickiness) 강화
- 고 가용성 AZ
- 클라우드 내에서 개인 트래픽과 공공 트래픽을 분리할 수 있음

[Elastic Load Balancing(ELB)]
- 관리형 로드 밸런서
- AWS가 관리하며 어떤 경우에도 작동할 것을 보장
- AWS가 업그레이드와 유지 관리 및 고가용성을 책임짐
- 로드 밸런서의 작동 방식을 수정할 수 있게끔 일부 구성 Knob 제공
- 무조건 쓰는 편이 좋음
- 자체 로드 밸런서를 마련하는 것보다 저렴
- 자체 로드 밸런서를 직접 관리하려면 확장성 측면에서 굉장히 번거롭기 때문
- 다수의 AWS의 서비스들과 통합되어 있음
- EC2 인스턴스와도 통합이 가능하며 스케일링 그룹, Amazon ECS와 인증서 관리(ACM), ClouldWatch, Route 53, WAF Global Accelerator 등 앞으로 더 늘어날 예정

[Health Check by ELB]
- Health Check는 ELB가 EC2 인스턴스의 작동이 올바르게 되고 있는지의 여부를 확인하기 위해 사용
- 제대로 작동하는 중이 아니라면 해당 인스턴스로는 트래픽을 보낼 수 없음
- 상태 확인은 포트와 라우트에서 이루어짐

[Types of load balancer on AWS]
- 클래식 로드 밸런서(V1 - 2009 - CLB)
1. HTTP, HTTPS, TCP, SSL (secure TCP)를 지원
2. AWS에서 이 로드밸런서 사용을 권장하지 않음

- Application 로드 밸런서(V2 - 2016- ALB)
1. HTTP, HTTPS, WebSocket 프로토콜 지원

- Network 로드 밸런서(V2 - 2017 - NLB)
1. TCP, TLS (secure TCP), UDP 프로토콜을 지원

- Gateway Load Balancer(2020 - GWLB)
1. 네트워크 층에서 작동하므로 3계층과 IP 프로토콜에서 작동

- 더 많은 기능을 가진 신형 로드 밸런서를 사용하는 것이 권장
- 일부 로드 밸런서들은 내부에 설정될 수 있어 네트워크에 개인적 접근이 가능
- 웹사이트와 공공 애플리케이션 모두에 사용이 가능한 외부 공공 로드 밸런서도 있음

[Load Balancer 보안 그룹]
- 유저는 HTTP나 HTTPS를 사용해 어디서든 로드 밸런서에 접근이 가능
- 포트 범위는 80 or 443
- 소스가 0.0.0.0/0이면 어디든 가능하다는 뜻
- EC2 인스턴스는 로드 밸런서를 통해 곧장 들어오는 트래픽만을 허용해야 하므로 EC2  인스턴스 보안 그룹 규칙은 달라야 함
- 포트 80에서 HTTP 트래픽을 허용하며
- 소스는 IP범위가 아니라 보안그룹이 됨
- EC2 인스턴스의 보안 그룹을 로드 밸런서의 보안 그룹으로 연결
- EC2 인스턴스는 로드 밸런서에서 온 트래픽 만을 허용하게 되는 강화된 보안 메커니즘이 됨

[Application Load Balancer(ALB)]
- 7계층, 즉 HTTP 전용 로드 밸런서
- 머신 간 다수 HTTP 애플리케이션의 라우팅에 사용
- 이러한 머신들은 target group이라는 그룹으로 묶이게 됨
- 동일 EC2 인스턴스 상의 여러 애플리케이션에 부하를 분산(ex. 컨테이너, ECS)
- HTTP/2, WebSocket 및 리다이렉트 지원
- HTTP에서 HTTPS로 트래픽을 자동 리다이렉트하려는 경우 로드밸런서 레벨에서 가능
- 경로 라우팅도 지원
1. target group에 따른 라우팅으로는 예를 들면, URL target route에 기반한 라우팅 가능(example.com/users or example.com/posts)
2. /users와 posts는 URL 상의 서로 다른 경로이고 이들은 다른 target group에 리다이렉트 가능
3. URL의 호스트 이름에 기반한 라우팅로 가능
4. 로드 밸런서가 one.example.com 또는 other.example.com에 접근이 가능하다고 하면 두 개의 다른 대상 그룹에 라우팅 가능
5. 쿼리 문자열과 헤더에 기반한 라우팅 가능(example.com/users?id=123&order=false가 다른 target group에 라우팅 가능)
- ALB는 마이크로 서비스나 컨테이너 기반 애플리케이션에 가장 좋은 로드 밸런서로 도커와 Amazon ECS의 경우 ALB가 가장 적합한 로드 밸런서가 됨
- 왜나하면 포트 매핑 기능이 있어 ECS 인스턴스의 동적 포트로의 리다이렉션을 가능하게 해줌
- CLB 뒤에서 다수의 애플리케이션을 사용하는 경우 실제 애플리케이션 개수만큼의 CLB가 필요
- ALB는 하나만으로 다수의 애플리케이션을 처리할 수 있음

[ALB Target Group]
- EC2 인스턴스
1. HTTP
2. 오토 스케일링 그룹에 의해 관리될 수 있음
- ECS 작업
1. HTTP
- 람다 함수
1. HTTP 요청이 JSON으로 변환됨
2. 람다함수는 AWS에서 무서버로 불리는 모든 것들의 기반이 되는 함수
3. 람다 함수 앞에도 ALB가 있을 수 있음
- IP Address
1. 꼭 private IP여야 함
- ALB는 여러 target group으로 라우팅할 수 있으므로 health check는 target group level에서 이루어짐

[ALB Good to know]
- CLB와 마찬가지로 ALB를 사용하는 경우에도 고정 호스트 이름이 부여
- 애플리케이션 서버는 클라이언트의 IP를 직접 보지 못하며 클라이언트의 실제 IP는 X-Forwarded-For라고 불리는 헤더에 삽입
- X-Forwarded-Port를 사용하는 포트와 X-Forwarded-Proto에 의해 사용되는 프로토콜도 얻게 됨
- 즉, 클라이언트의 IP인 12.34.56.78이 로드 밸런서와 직접 통신하여 연결 종료 기능을 수행
- 로드 밸런서가 EC2 인스턴스와 통신할 때 사설 IP인 로드 밸런서 IP를 사용해 EC2 인스턴스로 들어감
- 그리고 EC2 인스턴스가 클라이언트 IP를 알기 위해서는 HTTP 요청에 있는 추가 헤더인 X-Forwarded-Port와 X-Forwarded-Proto를 확인해야 함

[Network Load Balancer(NLB)]
- L4 로드 밸런서이므로 TCP와 UDP 트래픽을 다룸(HTTP를 다루는 L7보다 하위 계층)
- 성능이 매우 높음(초당 수백만 건의 요청을 처리할 수 있고 지연시간이 400ms인 ALB에 비해 100ms로 지연시간도 짧음)
- AZ별로 하나의 고정 IP를 가짐
- 탄력적 IP 주소를 각 AZ에 할당 가능
- 여러 개의 고정 IP를 가진 애플리케이션을 노출할 때 유용
- 탄련적 IP를 사용할 수 있으므로 1~3개의 IP로만 엑세스할 수 있는 애플리케이션에 고려 가능
- AWS 프리티어에 포함되지 않음
- 백엔드, 프론트엔드 모두 TCP 트래픽을 사용하거나 백엔드에서는 HTTP를 프론트엔드에서는 TCP를 사용할 수 있음

[NLB - Target Group]
- EC2 인스턴스
1. NLB가 TCP 또는 UDP 트래픽을 EC2 인스턴스로 리다이렉트 할 수 있음
- IP Address
1. IP 주소는 반드시 하드코딩되어야 하고 private IP여야 함
2. 자체 EC2 인스턴스의 private IP를 보낼 수 도 있지만 자체 데이터 센터 서버의 private IP를 사용할 수 있기 때문
3. 둘 다 같은 NLB를 앞에 사용 가능하기 때문
- ALB
1. NLB를 ALB 앞에 배치하는 경우
2. NLB 덕분이 고정 IP 주소를 얻을 수 있고 ALB 덕분에 HTTP 유형의 트래픽을 처리하는 규칙을 얻을 수 있기 때문
- NLB Target Group이 수행하는 Health Check
1. TCP, HTTP, HTTPS 프로토콜 지원
2. 백엔드 애플리케이션이 HTTP, HTTPS 프로토콜을 지원한다면 해당 프로토콜에 대한 상태확인을 정의할 수 있음

[Gateway Load Balancer(GWLB)]
- 가장 최신 로드 밸런서
- 배포 및 확장과 AWS의 타사 네트워크 가상 어플라이언스의 플릿 관리에 사용
- 네트워크의 모든 트래픽이 방화벽을 통과하게 하거나 침입 탐지 및 방지 시스템에 사용
- 그래서 IDPS나 심층 패킷 분석 시스템 또는 일부 페이로드를 수정할 수 있지만 네트워크 수준에서 가능
- GWLB 생성 시 VPC에서 라우팅 테이블 업데이트
- 그 후 모든 트래픽이 GWLB와 타사 가상 어플라이언스를 통과해 모든 네트워크 트래픽을 분석하고 드롭시킬 수 있음
- GWLB의 기능은 네트워크 트래픽을 분석하는 것 등
- 6081번 포트의 GENEVE 프로토콜을 사용하면 바로 GWLB가 됨

[GWBL 원리]
- GWLB는 IP 패킷의 네트워크 계층인 L3
- 투명 네트워크 게이트 웨이
1. VCP의 모든 트래픽이 GWLB가 되는 단일 엔트리와 출구를 통과하기 때문
- 로드 밸런서
1. target group의 가상 어플라이언스 집합에 전반적으로 트래픽을 분산

[GWLB Target Group]
- 타사 어플라이언스
1. EC2 인스턴스, 인스턴스 ID
2. IP 주소(Private IP)
3. 예를 들어 자체 네트워크나 자체 데이터 센터에서 이런 가상 어플라이언스를 실행하면 IP로 수동 등록 가능

[Elastic Load Balancer - Sticky Sessions]
- Stickiness or Sticky Session으로 실행하는 것으로 클라이언트가 로드 밸런서에 두 번 요청을 했을 때  백엔드에 첫번째에 응답했는 동일한 인스턴스로 요청을 보냄 
- 2개의 EC2 인스턴스와 3개의 클라이언트가 있는 ALB 같은 것
- 클라이언트에서 로드 밸런서로 요청의 일부로서 쿠키가 전송됨
- 고정성과 만료 기간이 있으므로 쿠키가 만료되면 클라이언트가 다른 EC2 인스턴스로 리디렉션 될 수 있음
- 세션 만료를 사용 시에는 사용자의 로그인과 같은 중요한 정보를 취하는 세션 데이터를 잃지 않기 위해 사용자가 동일한 백엔드 인스턴스에 연결됨
- 고정성이 활성화되면 백엔드 EC2 인스턴스 부하에 불균형을 초래할 수 있음
- 일부 인스턴스는 고정 사용자를 갖게 됨

[Sticky Sessions - Cookie]
- Application-based Cookies
1. 대상으로 생성된 사용자 정의 쿠키로 애플리케이션에서 생성
2. 애플리케이션에 필요한 모든 사용자 정의 속성을 포함할 수 있음
3. 쿠키 이름은 각 대상 그룹 별로 개별적으로 지정해야함
4. AWSALB, AWSALBAPP, AWSALBTG는 ELB에서 사용하는 이름이므로 지정 불가
5. 또는 애플리케이션 쿠키가 될 수 있는데 로드 밸런서 자체에서 생성
6. ALB의 쿠키 이름은 AWSALBAPP
7. 애플리케이션에서 기간을 지정할 수 있음

- Duration-based Cookies
1. 로드 밸런서에서 생성되는 쿠키
2. ALB에서는 이름이 AWSALB
3. CLB에서는 이름이 AWSELB
4. 특정 기간을 기반으로 만료되며 그 기간이 로드 밸런서 자체에서 생성

[ELB Cross Zone Load Balancing]
- 두 개의 AZ, 한쪽에는 EC2 인스턴스 2개짜리 로드밸런서, 다른 한쪽은 8개짜리 로드밸런서가 있는 불균형한 상황을 가정
- 클라이언트가 트래픽을 50%씩 두개의 AZ로 보냈다고 해도 10개의 EC2 인스턴스가 각각 10%씩 할당 받는 것이 Cross Zoen Load Balancing
- Cross Zoen Load Balancing을 사용하지 않는다면 AZ1의 인스턴스 들은 25%씩 AZ2의 인스턴스 들은 6.25%씩 각 AZ 안에서 부하가 분산

[로드 밸런서 별 Cross Zone Load Balancing]
- ALB
1. Cross Zone Load Balancing 활성화가 default
2. 대상 그룹 설정에서 비활성화 가능
3. 활성화가 default이므로 데이터를 다른 AZ로 옮기는 데 비용이 발생하지 않음

- NLB & GWLB
1. Cross Zone Load Balancing 비활성화가 default
2. 활성화를 하려면 비용 발생
3. AWS에서는 데이터를 다른 AZ로 옮길 때 비용을 지불해야 하므로

- CLB
1. Cross Zone Load Balancing 활성화가 default
2. 활성화시켜도 AZ 간 데이터 이동에 비용이 들지 않음

[ELB - SSL/TLS 인증서]
- in-flight 암호화 : SSL 인증서는 클라이언트와 로드 밸런서 사이에서 트래픽이 이동하는 동안 암호화
- 송신자와 수신자 측에서만 이를 복호화 가능
- SSL(Secure Sockets Layer)은 connections을 암호화하는데 사용
- TLS(Transport Layer Security)는 SSL의 새로운 버전이고 최근에는 TLS 인증서를 주로 사용
- public SSL 인증서는 CA(Certificate Authorities)에서 발급
- CA에는 Comodo, Symantec, GoDaddy, GlobalSign, Digicert, Letsencrypt 등이 있음
- public SSL 인증서를 로드 밸런서에 추가하면, 클라이언트와 로드 밸런서 사이의 connection을 암호화 가능
- 구글 등 웹사이트를 방문했을 때 녹색 표시 같은게 뜨는데, 트래픽이 암호화되고 있다는 뜻
- 트래픽이 암호화되지 않고 있을 때는 빨간색 표시가 뜨면서 트래픽이 암호화되지 않았으니 신용 카드 정보나 개인 정보 같은 걸 넣지 말라고 알려줌
- SSL 인증서에는 만료 날짜가 있어서 주기적으로 갱신해 인증 상태를 유지해야 함

[로드 밸런서에서 SSL의 동작]
- 사용자가 HTTPS(S가 붙은 건 SSL 인증서를 사용한다는 뜻)를 통해 접속
- 인터넷을 통해 우리 로드 밸런서에 접속하면 로드 밸런서에서는 내부적으로 SSL Termination을 수행
- 백엔드에서는 암호화되지 않은 상태 HTTP로 EC2 인스턴스와 통신
- VPC로 이동하는 트래픽은 private 네트워크를 사용하기 때문에 안전하게 보호됨
- 로드 밸런서는 X.509 인증서를 사용하는 데, 이를 SSL or TLS 서버 인증서라고 부름
- AWS에는 이 인증서들을 관리할 수 있는 ACM(AWS Certificate Manager)이라는 게 있음
- 사용자가 가진 인증서를 ACM에 업로드 가능
- HTTPS Listener
1. HTTP 리스너를 구성할 때 반드시 'HTTPS' 리스너로 해야됨
2. 기본 인증서를 지정
3. 다중 도메인을 지원하기 위해 다른 인증서를 추가할 수 있음
4. 클라이언트는 SNI(서버 이름 지정)라는 걸 사용하여 접속할 호스트 이름을 알릴 수 있음
5. 사용자가 원하는 대로 보안 정책 지정 가능(구 버전의 SSL과 TLS, 즉 레거시 클라이언트를 지원 가능)

[SSL - Server Name Indication]
- 여러 개의 SSL 인증서를 하나의 웹 서버에 로드해 하나의 웹 서버가 여러 개의 웹 사이트를 지원할 수 있게 함
- 최초 SSL 핸드셰이크 단계 에서 확장된 프로토콜로, 클라이언트가 대상 서버의 호스트 이름을 지정하도록 함
- 그러면 클라이언트가 접속할 웹사이트를 말했을 때, 서버는 어떤 인증서를 로드해야 하는지 알 수 있음
- 확장된 프로토콜이므로 ALB, NLB, CloudFront에서만 동작
- CLB는 구 버전이므로 동작하지 않음
- SNI는 다중 SSL 인증서를 사용해서 서버 이름을 지정하여 여러 개의 대상 그룹과 웹사이트를 지원할 수 있음
 
[SSL 인증서 지원 항목]
- CLB를 지원하긴 하지만 SSL 인증서를 하나만 둘 수 있음
- CLB 자체를 여러 개 둬야 여러 개의 인증서로 여러 호스트 이름을 지원할 수 있음
- ALB는 V2 밸런서로 SNI를 사용하여 여러 개의 SSL 인증서를 두고 리스너를 여러 개 지원할 수 있음
- NLB 역시 SNI를 사용하여 여러 개의 SSL 인증서로 다중 리스너 지원

[ELB - Connection Draining]
- CLB를 사용할 경우 Connection Draining
- ALB or NLB를 사용할 경우 Deregistration Delay라고 부름
- 인스턴스가 등록 취소, 혹은 비정상인 상태에 있을 때 인스턴스에 어느 정도 시간을 주어 in-flight 요청 즉 활성 요청을 완료할 수 있도록 하는 기능
- 인스턴스가 Draining 되면 ELB는 등록 취소 중인 EC2 인스턴스로 새로운 요청을 보내지 않음
- connection draining 파라미터는 매개변수로 표시할 수 있는 데 1~3600초 사이 값으로 설정 가능
- default는 300초(5분)
- 이 값을 0으로 설정하면 전부 다 비활성화 가능(draining도 일어나지 않는다는 뜻)
- 짧은 요청의 경우 낮은 값으로 설정
1. 1초보다 짧은 요청인 경우 connection draining 파라미터를 30초 정도로 설정)
2. 그래야 EC2 인스턴스가 빠르게 드레이닝 될테고 그 후에 오프라인 상태가 되어 교체 등의 작업을 할 수 있음
- 요청 시간이 매우 긴 요청 등의 경우 어느 정도 높은 값으로 설정
1. EC2 인스턴스가 금방 사라지지 않음
2. connection draining 과정이 완료되기를 기다려야 함

[Auto Scaling Group(ASG)]
- 웹사이트나 애플리케이션을 배포할 때 방문자가 갈수록 많아지면서 로드가 바뀔 수 있음
- 그리고 AWS에서 EC2 인스턴스 생성 API 호출을 통해 서버를 빠르게 생성하고 종료 가능
- 이를 자동화하고 싶다면 ASG 생성
- ASG의 목표
1. Scale out : 증가한 로드에 맞춰 EC2 인스턴스 추가
2. Scale in : 감소한 로드에 맞춰 EC2 인스턴스를 제거
3. 따라서 ASG 크기는 시간이 지나면서 변할 것임
4. ASG에서 실행되는 EC2 인스턴스의 최소 및 최대 개수를 보장하기 위해 매개변수를 전반적으로 정의 가능
5. 로드 밸런서와 페어링하는 경우 ASG에 속한 모든 EC2 인스턴스가 로드 밸런서에 연결됨
6. 한 인스턴스가 비정상이면 종료하고 이를 대체할 새 EC2 인스턴스 생성
- ASG는 무료이며 EC2 인스턴스와 같은 생성된 하위 리소스에 대한 비용만 지불

[ASG 동작]
- 최소 용량(ASG 내 인스턴스 최소 개수) 설정
- 희망 용량(ASG 내 인스턴스 희망 개수) 설정
- 최대 용량(ASG 내 인스턴스 최대 개수) 설정
- 최대 용량 내에서 희망 용량을 더 높은 숫자로 설정하면 스케일 아웃이 됨
- ASG에 n개의 인스턴스가 등록되어 있으면 ELB가 모든 인스턴스에 트래픽을 즉시 분산하여 사용자가 로드 밸런싱된 웹사이트에 엑세스 가능토록 함
- ELB는 상태 확인을 통해 EC2 인스턴스의 상태를 확인하고 ASG로 전달
- 로드 밸런서가 비정상이라 판단하는 EC2 인스턴스를 ASG가 종료
- 스케일 아웃(EC2 인스턴스 추가)되면 ELB가 트래픽을 보내고 로드를 분산

[ASG 속성]
- 인스턴스 속성을 기반으로 ASG를 생성하려면 시작 템플릿(Launch Template)을 생성
- 시작 템플릿에는 ASG 내에서 EC2 인스턴스를 시작하는 방법에 대한 정보가 포함
1. AMI 및 인스턴스 유형
2. EC2 사용자 데이터
3. EBS 볼륨
4. 보안 그룹
5. SSH key pair
6. EC2 인스턴스의 IAM Role
7. 네트워크 및 서브넷 정보
8. 로드 밸런서 정보
- 위 매개 변수는 EC2 인스턴스를 생성할 때 지정한 매개변수와 매우 유사
- 또한, ASG의 최소 크기, 최대 크기, 초기 용량을 정의해야 함
- 스케일링 정책 또한 정의해야 함

[Auto Scaling - CloudWatch Alarms & Scaling]
- CloudWatch Alarm을 기반으로 ASG를 스케일 인 및 스케일 아웃 가능
- 평균 CPU나 원하는 사용자 지정 지표(metric)을 지정하여 모니터링
- 예를 들어 평균 CPU가 너무 높으면 지표에 따라 경보가 울리고 경보가 ASG의 스케일 아웃 활동을 유발
- 경보에 의해 내부에서 자동적인 스케일링 이루어짐
- 경보를 기반으로 스케일 아웃 정책을 만들어 인스턴스 수를 늘리거나 스케일 인 정책을 만들어 인스턴스 수를 줄임

[ASG - Dynamic Scaling Policies]
- Target Tracking Scaling
1. 가장 단순하고 설정하기 쉬움
2. 예를 들어 모든 EC2 인스턴스에서 Auto Scaling 그룹의 평균 CPU 사용률을 추적하여 이 수치가 40%대에 머무를 수 있도록 할 때 사용
3. 이처럼 기본 기준선을 세우고 상시 가용이 가능하게 함

- Simple / Step Scaling
1. CouldWatch 경보를 설정
2. 예를 들어 전체 ASG에 대한 CPU 사용률이 70% 초과하는 경우 두 Unit 추가 설정 추가 가능
3. 예를 들어 전체 ASG 내의 CPU 사용률이 30% 이하로 떨어지면 Unit 하나를 제거 설정 추가 가능
4. CouldWatch 경보를 설정할 때 한 번에 추가할 유닛 수와 제거할 유닛 수를 단계별로 설정할 필요가 있음

- Scheduled Actions
1. 이미 알고있는 사용 패턴을 바탕으로 스케일링 예상
2. 예를 들어 금요일 오후 5시에 큰 이벤트가 예정되어 있으니 ASG 최소 용량을 매주 금요일 오후 5시마다 자동으로 10까지 늘리도록 설정
3. 스케일링이 필요함을 미리 알 때에 예정된 작업 설정

- Predictive Scaling
1. AWS 내 Auto Scaling 서비스를 활용하여 지속적으로 예측 생성
2. 과거 load를 분석하고 다음 Scaling을 예측
3. 해당 예측을 기반으로 사전에 스케일링 작업 예약
4. 머신 러닝 기반

[스케일링 지표]
- CPUUtilization
1. 인스턴스에 요청이 갈 때마다 연산을 수행되어야 하므로 일부 CPU가 사용됨
2. 모든 인스턴스의 평균 CPU 사용률을 봤을 때 이 수치가 올라가면 인스턴스가 잘 사용되고 있다는 의미

- RequestCountPerTarget
1. EC2 인스턴스는 한 번에 대상 별로 1,000개의 요청까지만 최적으로 작동
2. 대상별 요청 수 지표라고 하며 각 EC2 인스턴스에 대한 미해결 요청 수

- Average Network In / Out
1. 예를 들어 업로드와 다운로드가 많아 EC2 인스턴스에 대해 해당 네트워크에서 병목 현상이 발생할 것으로 판단 
2. 평균 네트워크 입출력량을 기반으로 스케일링 수행
3. 특정 임계값에 도달할 때 스케일링을 수행하도록 설정 가능

- Any custom metric
1. 직접 CloudWatch에서 애플리케이션 별로 지표를 설정하고 이를 기반으로 스케일링 정책을 바꿀 수 있음

[ASG - Scaling Cooldown]
- 스케일링 작업이 끝날 때마다 인스턴스의 추가 또는 삭제 상관없이 기본적으로 5분의 휴지 기간을 갖는 것
- 휴지 기간에는 ASG가 추가 인스턴스를 실행 또는 종료할 수 없음
- 이는 지표를 이용하여 새로운 인스턴스가 안정화될 수 있도록 하며 어떤 새로운 지표의 양상을 살펴보기 위함
- 따라서 스케일링 작업 발생 시 기본으로 설정된 휴지가 있는지 확인해야 함
- 그럴 경우 해당 작업을 무시하고 아닐 경우 인스턴스 실행 또는 종료하는 스케일링 작업 수행
- 즉시 사용 가능한 AMI를 이용하여 EC2 인스턴스 구성 시간을 단축하고 이를 통해 요청을 좀 더 신속히 처리하는 것이 좋음
- EC2 인스턴스 구성에 할애되는 시간이 적으면 즉시 적용 가능
- 이렇게 활성화 시간이 빨라지면 휴지 기간 또한 단축되므로 ASG 상에서 더 많은 동적 스케일링이 가능
- 또한, ASG가 일 분마다 지표에 접근할 수 있도록 세부 모니터링 기능 등을 사용하도록 설정하고 이와 같은 지표를 신속히 업데이트할 필요가 있음

[Amazon RDS(Relational Database Service)]
- SQL을 쿼리 언어로 사용하는 관리형 데이터베이스 서비스
- SQL은 데이터베이스를 쿼리하는 구조화된 언어
- 클라우드의 RDS 서비스에 DB를 생성할 수 있고 AWS가 DB를 관리
- AWS가 관리하는 DB 엔진 유형
1. PostgreSQL
2. MySQL
3. MariaDB
4. Oracle
5. Microsoft SQL Server
6. Aurora (AWS Proprietary database)

[RDS의 장점]
- RDS는 관리형 서비스이며 AWS는 데이터베이스뿐만 아니라 다양한 서비스 제공
- DB 프로비저닝과 기본 운영체제 패치가 완전 자동화됨
- 지속적으로 백업이 생성되므로 특정 시점(타임스탬프)으로 복원 가능
- 데이터베이스의 성능을 대시보드에서 모니터링할 수 있음
- 읽기 전용 복제본을 활용하여 읽기 성능 개선
- 재해 복구 목적으로 다중 AZ 설정
- 유지 관리 기간에 업그레이드 가능
- 인스턴스 유형을 늘려 수직 확장하거나 읽기 전용 복제본을 추가하여 수평 확장 가능
- 파일 스토리지는 EBS(gp2 or io1)에 구성

[RDS의 단점]
- RDS 인스턴스에 SSH 엑세스할 수 없음
- 관리형 서비스이므로 AWS가 서비스를 제공하지만 기본 EC2 인스턴스에는 엑세스할 수 없음
- 그러나 EC2 인스턴스에 데이터베이스 엔진을 배포할 때 설정할 모든 것을 AWS가 제공

[RDS - Storage Auto Scaling ☆]
- 데이터베이스를 많이 사용하면 공간이 부족해질 수 있는데 RDS 스토리지 오토 스케일링 기능이 활성화되어 있으면 RDS가 이를 감지하여 자동으로 스토리지를 확장해줌
- 스토리지 용량을 늘리기 위해 DB를 다운시키는 등의 작업을 할 필요가 없음
- 애플리케이션이 RDS 데이터베이스에서 읽기와 쓰기 작업을 많이 하면 임곗값에 도달하게 되고 RDS가 자동으로 스토리지를 오토 스케일링
- 데이터베이스 스토리지를 수동으로 확장하는 작업을 피할 수 있게 해줌
- 이를 위해 최대 스토리지 임계값(스토리지를 확장할 최대치)을 설정
- 워크로드를 예측할 수 없는 애플리케이션에서 굉장히 유용하고 모든 RDS 데이터베이스 엔진(PostgreSQL, MySQL, MariaDB, Oracle, Microsoft SQL Server)에서 지원됨
- 예시
1. 남은 공간이 10%미만이 되면 스토리지 자동 수정
2. 스토리지 부족 상태가 5분 이상 지속되면 스토리지 자동 확장
3. 지난 수정으로부터 6시간이 지났을 경우 오토 스케일링이 활성화되어 있다면 스토리지 자동 확장

[RDS Read Replicas]
- 읽기 전용 복제본은 읽기를 스케일링
- 예시
1. 애플리케이션과 RDS 데이터베이스 인스턴스가 있는 상황
2. 애플리케이션은 DB 인스턴스에 대해 읽기와 쓰기 수행
3. 하지만 주된 DB 인스턴스가 너무 많은 요청을 받아 충분히 스케일링 할 수 없으므로 읽기를 스케일링
4. 이때 읽기 전용 복제본을 최대 15개까지 생성할 수 있음
5. 이들은 동일한 AZ 또는 AZ나 리전을 걸쳐서 생성될 수 있음(Within AZ, Cross Az, Cross Region ☆)
6. main DB 인스턴스와 두개의 읽기 전용 복제본 사이에 비동기식 복제 발생
7. 비동기식이란 읽기가 일관적으로 유지된다는 뜻
8. 가령 애플리케이션에서 데이터를 복제하기 전 읽기 전용 복제본을 읽어들이면 모든 데이터를 얻을 수 있음(일관적인 비동기식 복제)
- 복제본이 읽기 스케일링에 적합할 수 있으나 이를 DB로도 승격할 수 있음
- DB로 사용하고자 하며 그에 대한 권한을 획득하면 이를 DB로 승격하여 복제 메커니즘에서 완전히 탈피
- 하지만 자체적인 생애 주기를 가짐
- 읽기 전용 복제본을 사용하려는 경우 main 애플리케이션에 있는 모든 Connection을 업데이트해야 하며 이를 통해 RDS 클러스터 상의 읽기 전용 복제본 전체 목록을 활용할 수 있음

[RDS Read Replicas - Use Cases]
- 예를 들어 평균적인 부하를 감당하는 Production App이 있다고 가정
- Production App에서는 메인 RDS DB 인스턴스에 대한 읽기 및 쓰기 수행
- 이때 새로운 팀이 와서 이 데이터를 기반으로 리포트 및 분석을 실시하고자 함
- 리포트 App을 메인 RDS DB 인스턴스에 연결하면 오버로드 발생 및 Production App의 속도가 느려짐
- 이를 피하기 위해 새로운 워크로드에 대한 읽기 전용 복제본 생성
- 읽기 전용 복제본을 생성하면 메인 RDS DB 인스턴스와 읽기 전용 복제본 간 비동기식 복제 발생
- 그 다음 리포드 App이 생성한 읽기 전용 복제본에서 읽기 작업과 분석을 실행
- 이 경우 Production App은 전혀 영향을 받지 않음
- 읽기 전용 복제본은 SELECT 명령문만 사용해야 함(DML 사용불가능)

[RDS Read Replicas - Network Cost]
- AWS에서는 하나의 AZ에서 다른 AZ로 데이터가 이동 시 비용 발생
- 하지만 예외가 존재하며 보통 관리형 서비스에서 예외가 발생
- RDS 읽기 전용 복제본은 관리형 서비스
- 읽기 전용 복제본이 다른 AZ 상이지만 동일한 리전 내에 있을 때 비용 발생하지 않음
- 하지만 서로 다른 리전에 복제본이 존재하는 경우 여러 리전을 넘나들어야 하기 때문에 네트워크에 대한 복제 비용 발생

[RDS Multi AZ(Disaster Recovery)]
- 다중 AZ는 주로 재해 복구에 사용
- 예시
1. AZ A에서 읽기와 쓰기를 수행하는 마스터 DB 인스턴스
2. 동기식으로 이를 AZ B에 스탠바이 인스턴스로 복제
3. 마스터 데이터베이스의 모든 변화를 동기적으로 복제
4. 이는 애플리케이션의 마스터에 쓰이는 변경사항이 대기 인스턴스에도 그대로 복제된다는 것을 의미
- 즉 하나의 DNS 이름을 갖고 App 또한 하나의 DNS 이름으로 통신하며 마스터에 문제가 생길 때에도 스탠바이 데이터베이스에 자동으로 장애 조치 수행(하나의 DNS 이름을 갖기 때문)
- 이를 통해 가용성을 높일 수 있으므로 다중 AZ라고 불림
- 전체 AZ or 네트워크가 손실될 때를 대비한 장애 조치이자 마스터 DB 인스턴스 또는 스토리지에 장애가 발생할 때 스탠바이 데이터베이스가 새로운 마스터가 될 수 있도록 하는 것
- 따로 App에 수동으로 조치할 필요가 없음
- 자동으로 DB에 연결 시도가 되고 장애 조치가 필요하게 될 때 스탠바이가 마스터로 승격되는 과정이 자동으로 이루어짐
- 스케일링에 이용되지도 않음
- 원하는 경우 재해 복구를 대비해서 읽기 전용 복제본을 다중 AZ로 설정 가능

[RDS - From Single AZ to Multi AZ]
- downtime이 전혀 없음
- 즉 단일 AZ에서 다중 AZ로 전환할 때 DB를 중지할 필요가 없음
- DB 수정을 클릭하고 다중 AZ 기능을 활성화시키기만 하면 됨(이외 작업 필요 없음)
- 이를 통해 RDS DB 인스턴스는 마스터와 스탠바이 데이터베이스를 확보
- 내부적인 과정
1. 기본 DB의 RDS가 자동으로 스냅샷 생성
2. 이 스냅샷은 새로운 스탠바이 DB에 복원
3. 스탠바이 DB가 복원되면 두 DB 간 동기화가 설정되므로 스탠바이 DB가 Main RDS DB 내용을 모두 수용하여 다중 AZ 설정 상태가 됨

[RDS Custom for Oracle and Microsoft SQL Server]
- RDS에서는 기저 운영 체제나 DB 사용자 지정 기능에 접근할 수 없음
- RDS Custom에서는 접근할 수 있음
- RDS Custom은 Oracle 및 Microsoft SQL Server에서만 사용 가능
- RDS를 통해 AWS에서의 DB 자동화 설정, 운영 그리고 스케일링의 장점을 모두 챙길 수 있음
- RDS Custom 옵션을 추가하면 기저 DB와 운영 체제에 접근할 수 있게 됨
1. 내부 설정 구성
2. Install patches
3. native 기능 활성화
4. SSH or SSM 세션 관리자를 사용해서 RDS 뒤에 있는 기저 EC2 인스턴스에 엑세스
- 사용자 지정 설정을 사용하려면 RDS가 수시로 자동화, 유지관리 or 스케일링과 같은 작업을 수행하지 않도록 자동화를 꺼두는 것이 좋음
- 이제 기저 EC2 인스턴스에 엑세스가 가능하여 문제가 쉽게 발생할 수 있으므로 데이터베이스 스냅샷을 만들어 두는 것이 좋음
- 그렇지 않으면 오류가 발생했을 때 복구가 어려움
- RDS는 데이터베이스 전체를 관리하며 운영체제와 나머지는 AWS에서 관리하고 있음
- AWS에서 관리하는 것은 사용자가 아무것도 안해도 됨

[Amazon Aurora]
- AWS의 고유 기술
- 오픈 소스는 아님
- Postgres 및 MySQL과 호환
- 클라우드에 최적화되어 있어 RDS의 MySQL보다 5배 높은 성능이고 RDS의 Postgres보다 3배 높은 성능
- Aurora의 스토리지는 자동으로 확장하여 10GB에서 시작하지만 DB에 더 많은 데이터를 넣을수록 128TB까지 자동으로 커짐
- 그래서 DB나 SysOps로써 저장 디스크를 신경쓰지 않아도 됨
- read replicas는 15개를 둘 수 있음(MySQL은 5개만 가능)
- 복제 속도도 훨씬 빠름
- 장애조치는 즉각적임(다중 AZ나 MySQL RDS보다 훨씬 빠름)
- 기본적으로 클라우드 네이티브이므로 가용성이 높음
- 비용은 RDS에 비해 약 20% 정도 높지만 스케일링 측면에서 훨씬 더 효율적이라서 오히려 비용 절감 가능

[Aurora의 가용성 및 Read Scaling]
- 3개의 AZ에 걸쳐 data를 기록할 때 6개의 사본(copy)을 저장
- 따라서 Aurora는 가용성이 높음
- 쓰기에는 6개의 사본 중 4개만 있으면 되므로 AZ 하나가 작동하지 않아도 괜찮음
- 읽기에는 6개 사본 중 3개만 있으면 되서 읽기 가용성이 높음
- 일종의 자가 복구 과정이 있음
- 일부 데이터가 손상되거나 문제가 있으면 백엔드에서 P2P 복제를 통한 자가 복구가 진행
- 단일 볼륨에 의존하지 않고 수 백 개의 볼륨을 사용
- 물론 사용자가 관리하지 않고 백엔드에서 진행하는 과정이며 리스크를 크게 감소
- 데이터가 기록되며 사본이 생길 때 각기 다른 볼륨에 기록되며 스트라이프(Striped) 형식으로 되어 매우 잘 작동함
- 하지만 실제 상호작용 대상은 스토리지가 아님
- Aurora는 RDS의 다중 AZ와 유사함
- 쓰기를 받는 인스턴스는 하나 뿐이므로 Aurora에도 마스터가 존재
- 마스터가 작동하지 않으면 평균 30초 이내에 장애 조치 시작되고 장애 조치가 매우 빠름
- 마스터 외에 읽기를 제공하는 읽기 전용 복제본을 15개까지 둘 수 있음
- 따라서 복제본을 많이 두고 읽기 워크로드를 스케일링할 수 있음
- 마스터에 문제가 생기면 읽기 전용 복제본 중 하나가 마스터가 되어 대체
- RDS와는 작동 방식이 꽤 다르다고 할 수 있지만 기본적으로 마스터가 하나인 건 동일
- 이 복제본들은 리전 간 복제 지원
- 즉 마스터는 하나, 복제본은 여럿이며 스토리지가 복제
- 그리고 작은 블록 단위로 자가 복구 또는 확장이 일어남

[Aurora DB Cluster]
- 마스터가 바뀌거나 장애 조치가 실행될 수 있으므로 Aurora에서는 Writer Endpoint를 제공
- Writer Endpoint는 DNS 이름으로 항상 마스터를 가리킴
- 따라서 장애 조치 후에도 클라이언트는 Writer Endpoint와 상호작용하게 되며 올바른 인스턴스로 자동으로 리다이렉트됨
- 읽기 전용 복제본을 15개까지 생성 가능하며 자동 스케일링을 설정해서 항상 적절한 수의 읽기 전용 복제본이 존재하도록 할 수 있음
- ☆ Reader Endpoint는 복제본이 어디에 있고 URL은 무엇이고 어떻게 연결되는지 사용자의 앱 입장에서 파악하기 힘든 것들을 파악할 수 있음
- Reader Endpoint는 Writer Endpoint와 정확히 같은 기능을 함
- Connection 로드 밸런싱에 도움을 줌
- 모든 읽기 전용 복제본과 자동으로 연결
- 따라서 클라이언트가 Reader Endpoint에 연결될 때마다 읽기 전용 복제본 중 하나로 연결되며 이런 방식으로 로드 밸런싱을 도와줌
- ☆ 로드 밸런싱은 statement(문장)가 아닌 Connection Level에서 일어남

[Aurora 기능]
- 자동 장애 조치
- 백업 및 복구
- 격리 및 보안
- 산업 규정 준수
- 자동 스케일링을 통한 버튼식 스케일링
- 제로 다운타임 자동 패치
- 고급 모니터링
- 통상 유지 관리
- 과거 특정 시점의 데이터로 복원하는 백트랙 기능(백업에 의존하지 않음)

[오로라 Replicas - Auto Scaling]
- 오로라 인스턴스의 리더 엔드포인트에서 많은 읽기 요청이 발생하면 아마존 오로라 DB의 CPU 사용량 증가
- 이 경우 복제본 오토 스케일링 설정 가능
- 아마존 오로라 복제본이 추가되고 리더 엔드포인트가 새 복제본을 처리하도록 확장됨
- 이 새로운 복제본은 트래픽을 받기 시작하고 읽기가 더 분산된 방식으로 발생하므로 전체 CPU 사용량을 낮춤

[오로라 - Custom Endpoints]
- 크기가 다른 두 가지 종류의 복제본이 있다고 가정
- 이렇게 하는 이유는 오로라 인스턴스의 하위 집합을 사용자 지정 엔드포인트로 지정하기 위함
- 더 큰 오로라 인스턴스에 사용자 지정 엔드포인트를 정의한다고 가정
- 이렇게 하는 이유는 이 인스턴스가 더 강력하므로 이 특정 복제본에 대해 분석 쿼리를 실행하는 것이 더 좋을 것으로 예상
- 사용자 지정 엔트포인트가 있는 경우, 일반적으로 리더 엔드포인트는 사용자 지정 엔드포인트를 정의한 후에는 사라지지 않지만 더 이상 사용되지 않음
- 실제로는 다양한 종류의 워크로드에 대해 많은 사용자 정의 엔드포인트를 설정해서 오로라 복제본의 하위 집합만 쿼리하게 됨

[오로라 Serverless]
- 실제 사용량에 따라 자동화된 DB 인스턴스화 및 오토 스케일링 제공
- 워크로드가 드물거나 간헐적이거나 예측할 수 없는 경우에 유용
- 용량 계획을 세울 필요 없음
- 스핀업되는 각 오로라 인스턴스의 초당 요금을 지불하게 되므로 훨씬 더 비용 효율적임
- 작동 방식
1. 클라이언트는 오로라에서 관리하는 Proxy Fleet과 Communication
2. 백엔드에서는 서버리스 방식으로 워크로드에 따라 많은 오로라 인스턴스가 생성
3. 따라서 용량을 미리 프로비저닝할 필요가 전혀 없음

[오로라 Multi-Master]
- Writer 노드에 대해 지속적인 쓰기 가용성을 원하는 경우
- 즉, 오로라 클러스터에서 모든 오로라 인스턴스는 Writer 노드
- 모든 오로라 인스턴스가 쓰기 요청을 받을 수 있음
- 일반적인 오로라 클러스터와 다른 케이스
- 하나의 새 마스터가 있고 그 마스터가 실패할 경우 다른 것이 새로운 마스터로 승격됨
- 클라이언트는 여러 개의 오로라 인스턴스에 대한 여러 DB Connection을 유지 할 수 있음
- 한 인스턴스에 장애가 발생하면 클라이언트가 다른 오로라 인스턴스를 쓸 수 있으므로 문제 없음

[Global 오로라]
- 리전 간 읽기 복제본이 있는 경우
- 재해 복구에 매우 유용
- 설치는 매우 간단
- 오로라 글로벌 DB를 설정할 수도 있음(현재 권장되는 방법)
- 기본 리전에서 읽기 및 쓰기 모두 발생
- 하지만 최대 5개의 보조 읽기 전용 리전도 있고 복제 지연이 1초 미만
- 보조 리전 당 최대 16개의 읽기 복제본을 설정 가능하여 전세계의 읽기 워크로드 지연 시간을 줄일 수 있음
- 또한, 한 리전에서 DB가 중단되는 경우, 재해 복구를 위해 다른 리전을 활성화하면 RTO, 즉 복구 시간 목표를 1분 미만으로 할 수 있음
- 다른 리전으로 복구하는 데 1분 미만이 걸림
- ☆"오로라 글로벌 DB의 데이터를 리전 간 복제하는 데 평균 1초 미만이 소요된다"라는 문장이 시험에 나오면 글로벌 오로라를 사용하라는 힌트

[오로라 Machine Learning]
- 오로라는 AWS 내의 머신러닝 서비스와도 통합되어 있음
- 오로라 머신러닝은 애플리케이션에 머신러닝 기반 예측을 SQL 인터페이스로 적용할 수 있음
- 이는 오로라와 다양한 머신러닝 서비스 간의 간단하고 최적화된 Secure 통합
- 두 가지 서비스 지원
1. Amazon SageMaker : 백엔드에서 모든 종류의 머신러닝 모델을 사용할 수 있게 해줌
2. Amazon Comprehand : 감성 분석 가능
- 즉 오로라 머신 러닝을 사용하기 위해 머신 러닝 경험이 없어도 됨
- 사용 사례는 사기 탐지, 광고 타겟팅, 감성 분석, 제품 추천 등
- 오로라는 AWS의 머신러닝 서비스에 연결되며 애플리케이션은 아주 간단한 SQL 쿼리만 실행하면 됨
- 예시
1. '추천 제품은 무엇인가요?' 요청
2. 오로라는 사용자 프로필이나 쇼핑 내역 등 데이터를 머신러닝 서비스로 전송
3. 그러면 머신러닝 서비스는 예측을 오로라에 직접 반환
4. 사용자가 빨간색 셔츠와 파란색 바지를 구매해야 한다고 예측하면 오로라는 애플리케이션에 SQL 쿼리 결과로 반환

[RDS Backups]
- 자동 백업
1. RDS 서비스가 DB 백업기간 동안 자동으로 매일 DB의 전체 백업을 수행
2. 5분마다 트랜잭션 로그가 백업
3. 즉, 가장 빠른 백업은 5분 전의 백업
4. 자동 백업을 통해 언제라도 5분 전으로 복원할 수 있음
5. 자동 백업 보존 기간은 1~35일 사이로 설정 가능
6. 이 기능을 사용하지 않으려면 0으로 설정하여 자동 백업을 사용하지 않도록 설정하면 됨

- 수동 DB 스냅샷
1. 사용자가 수동으로 트리거
2. 자동 백업은 만료되는 반면, 수동으로 한 백업을 원하는 기간동안 유지 가능
3. 예를 들어 RDS DB가 있는데, 한 달에 2시간만 사용하는 걸 알고 있다고 가정
4. DB를 중지해도 스토리지 비용을 계속 지불해야 함
5. ☆따라서, 두 시간 동안 사용한 후 스냅샷을 만든 다음, 원본 DB를 삭제하면 됨
6. 스냅샷은 RDS DB의 실제 스토리지 비용보다 훨씬 저렴
7. DB를 다시 사용할 준비가 되면, 스냅샷을 복원하여 사용

[오로라 Backups]
- 자동 백업
1. 1일에서 35일까지 유지 가능한 자동화된 백업
2. RDS에서는 비활성화할 수 있지만 오로라에서는 비활성화 불가능
3. 해당 기간의 어느 시점으로든 복구할 수 있는 시점 복구 기능

- 수동 DB 스냅샷
1. 사용자가 수동으로 트리거할 수 있으며, 원하는 기간동안 유지 가능
2. 오로라 백업과 RDS 백업 매우 비슷

[RDS & 오로라 Restore options]
- RDS / 오로라 백업 또는 스냅샷은 새 DB로 복원 가능
- 자동화된 백업이나 수동 스냅샷을 복원할때마다 새 DB가 생성
- S3에서 MySQL DB를 복원 가능
1. S3는 AWS의 클라우드 객체를 저장하는 방법
2. 온프레미스 DB의 백업을 생성한 다음 객체 스토리지인 아마존 S3에 배치
3. RDS에는 아마존 S3에서 백업 파일을 MySQL을 실행하는 새 인스턴스로 복원하는 옵션이 있음
- SE에서 MySQL 오로라 클러스터로 복원하는 경우
1. 온프레미스 DB를 다시 백업하면 됨
2. 외부적으로 Percona XtraBackup이라는 소프트웨어를 사용
3. Percona XtraBackup의 백업 파일을 아마존 S3로 보내어 거기서 백업을 MySQL을 실행하는 새 오로라 클러스터로 복원 가능
4. 차이점은 RDS MySQL로 복원할 때는 DB 백업만 있으면 됨
5. 오로라 MySQL에서는 Percona XtraBackup으로 백업한 다음, S3에서 오로라 DB 클러스터로 백업하면 됨

[오로라 DB 복제]
- 기존 DB 클러스터에서 새로운 오로라 DB 클러스터를 생성 가능
- 예를 들어 오로라에 Production DB가 있고, 거기에서 테스트를 실행하고 싶다고 가정
- 테스트 애플리케이션은 Staging 환경에 있어야 해서 데이터를 복사하고 싶음
- 이 경우 Production 오로라 DB를 복제하면 됨
- 그러면 새 DB가 생성되는데 예를 들어 스테이징 오로라 DB라고 부름
- 복제는 copy-on-write 프로토콜을 사용하기 때문에 스냅샷을 찍고 복원하는 것보다 매우 빠름
- 처음 DB 복제본을 만들 때는, 원래 DB 클러스터와 동일한 데이터 볼륨을 사용하므로 데이터를 복사하지 않아 빠르고 효율적임
- Production 오로라 DB 또는 Staging 오로라 DB에 업데이트가 이루어지면 새로운 추가 스토리지가 할당되고, 데이터가 복사 및 분리됨(두 가지 장점 모두 누림)
- 데이터베이스 복제는 빠르고 비용 효율적으며, Production DB에 영향을 주지 않고, Production DB에서 DB를 복제하는 데 매우 유용
- 스냅샷 및 복원 기능 필요없음

[RDS & 오로라 Security]
- At-rest 암호화(저장 데이터 암호화)
1. RDS 및 오로라 DB에 저장된 데이터를 암호화 가능
2. 이는 데이터가 볼륨에 암호화된다는 뜻
3. KMS를 사용해 마스터와 모든 복제본의 암호화가 이루어지며 이는 DB를 처음 실행할 때 정의됨
4. 어떤 이유에서든 마스터 DB를 암호화하지 않았다면 읽기 전용 복제본을 암호화할 수 없음
5. 또한, 암호화 되어 있지 않은 기존 DB를 암호화하려면 암호화되지 않은 DB의 DB 스냅샷을 가지고 와서 암호화된 DB 형태로 DB 스냅샷을 복원해야 함
6. 따라서 스냅샷 생성 및 복원 작업을 거쳐야 함

- In-flight 암호화(클라이언트와 DB 간의 전송 중 데이터 암호화)
1. 기본적으로 전송 중 데이터 암호화 기능을 갖추고 있음
2. 따라서 클라이언트는 AWS 웹사이트에서 제공하는 AWS의 TLS 루트 인증서를 사용해야함

- IAM Authentication
1. DB 인증을 살펴보면 RDS와 오로라이므로 사용자 이름과 패스워드라는 전통적인 조합을 사용할 수 있음
2. 그러나 AWS이기도 하므로 IAM 역할을 사용해서 DB에 접속할 수 있음
3. 예를 들어 EC2 인스턴스에 IAM 역할이 있다면 이를 사용해 사용자 이름이나 패스워드 없이 직접 DB를 인증 가능
4. 이는 AWS 내의 모든 보안 기능을 IAM으로 관리하는 데 도움이 됨

- Security Groups (보안 그룹)
1. 보안 그룹을 사용해서 DB에 대한 네트워크 엑세스를 통제할 수 있음
2. 특정 포트, IP, 보안 그룹을 허용하거나 차단할 수 있음

- No SSH available(RDS 커스텀 예외)
1. RDS와 오로라에는 SSH 엑세스가 없음(관리형 서비스가 있기 때문)
2. 다만 AWS의 RDS 커스텀 서비스를 사용한다면 예외

- Audit Logs(감사 로그)
1. 감사 로그가 있어서 시간에 따라 RDS 및 오로라에서 어떤 쿼리가 생성되고 있고 DB를 확인하려면 감사 로그 작성을 활성화하면 됨
2. 로그는 시간이 지나면 자동으로 삭제되며 장기간 보관하고 싶다면 AWS에 있는 CloudWatch Logs라는 전용 서비스로 전송해야함

[아마존 RDS 프록시]
- VPC 내에 RDS DB를 배포할 수 있음
- 완전 관리형 RDS DB 프록시도 배포 가능
- 아마존 RDS 프록시를 사용하면 애플리케이션이 DB 내에서 DB Connection 풀을 형성하고 공유 가능
- 애플리케이션을 RDS DB 인스턴스에 일일이 연결하는 대신 프록시에 연결하면 프록시가 하나의 풀에 Connection을 모아 RDS DB 인스턴스로 가는 Connection이 줄어듬
- ☆RDS DB 인스턴스에 Connection이 많은 경우 CPU와 RAM 등 DB 리소스의 부담을 줄여 DB 효율성을 향상시킬 수 있고 DB에 개방된 Connection과 시간 초과를 최소화할 수 있기 때문
- RDS 프록시는 완전한 Serverless로 오토 스케일링이 가능해 용량을 관리할 필요가 없고 가용성이 높음
- 다중 AZ도 지원
- 가령 RDS DB 인스턴스에 장애 조치가 발생하면 기본 인스턴스가 아니라 대기 인스턴스로 실행되며 RDS 프록시 덕분에 RDS와 오로라의 장애 조치 시간을 66%까지 줄일 수 있음
- 메인 RDS DB 인스턴스에 애플리케이션을 모두 연결하고 장애 조치를 각자 처리하게 하는 대신 장애 조치와 무관한 RDS 프록시에 연결하는 것
- ☆RDS 프록시가 장애 조치가 발생한 RDS DB 인스턴스를 처리하므로 장애 조치 시간 개선
- RDS 프록시는 MySQL, PostgreSQL, MariaDB용 RDS를 지원하며 MySQL, PostgreSQ용 오로라를 지원
- 애플리케이션 코드를 변경하지 않아도 되고 RDS DB 인스턴스나 오로라 DB에 연결하는 대신 RDS 프록시에 연결하기만 하면 됨
- RDS 프록시는 DB에 IAM 인증을 강제함으로써 IAM 인증을 통해서만 RDS DB 인스턴스에 연결하도록 할 수 있음
- 이때 자격 증명은 AWS Secrets Manager 서비스에 안전하게 저장됨
- RDS는 public access가 절대로 불가능
- VPC 내에서만 엑세스할 수 있음
- 인터넷을 통해 RDS 프록시에 연결할 수 없으니 보안이 휼륭함
- RDS 프록시를 사용하면 코드 조각을 실행하는 Lambda 함수를 사용할 수 있음
- Lambda 함수는 증식하며 여러 개가 생성되고 사라지는 속도가 매우 빠름
- RDS DB 인스턴스에 수만 개의 Lambda 함수가 순식간에 발생했다 사라지며 Connection을 개방한다고 가정하면 개방된 Connection에 시간 초과가 발생하여 난장판됨
- 따라서 RDS 프록시를 사용하여 Lambda 함수의 Connection 풀을 생성하면 Lambda 함수가 RDS 프록시를 오버로드함
- RDS 프록시가 풀을 생성하면 RDS DB 인스턴스 Connection이 줄어 문제 해결 가능

[ElastiCache]
- RDS가 관계형 DB를 관리하는 것과 같은 방식
- ElastiCache는 캐싱 기술인 Redis 또는 Memcached를 관리할 수 있도록 도와줌
- 캐시는 매우 높은 성능과 짧은 지연 시간을 가진 인메모리 DB
- 캐시는 읽기 집약적인 워크로드에서 DB의 로드를 줄여줌
- 일반적인 쿼리는 캐시에 저장되므로 매번 DB를 쿼리하지 않아도 됨
- 캐시만 사용하여 쿼리의 결과 검색 가능
- 또한, 애플리케이션의 상태를 Amazon ElastiCache에 저장해서 애플리케이션을 stateless(상태 비저장형)으로 할 수 있음
- RDS와 동일한 이점이 있기 때문에, AWS는 DB의 운영체제를 유지 관리할 수 있음
- 패치, 최적화, 설정, 구성, 모니터링, 장애복구 백업 등
- 아마존 ElastiCache를 사용하는 경우, 캐시는 껏다 켰다하면 되는 게 아니므로 애플리케이션의 코드를 많이 바꿔야 함
- 그러므로 캐시를 쿼리하도록 애플리케이션을 DB를 쿼리하기 전이나 후에 변경해야 함

[ElastiCache Solution 아키텍처 - DB Cache]
- 쿼리가 이미 발생했는지 확인하기 위해 ElastiCache를 쿼리함
- 이미 발생하여 ElastiCache에 저장되어 있다면 바로 ElastiCache에서 결과를 가져오는 것을 캐시 히트라고 함
- 쿼리를 수행하기 위해 DB로 이동하는 시간이 절약됨
- 캐시 미스가 발생하면 DB에서 데이터를 가져와야 함
- 다른 애플리케이션이나 다른 인스턴스에서 같은 쿼리가 발생하면 데이터를 캐시에 다시 쓸 수 있음
- 다음에 동일한 쿼리가 일어나면 캐시 히트 발생
- 이로 인해 RDS DB의 로드를 줄이는 데 도움이 됨
- 데이터를 캐시에 저장하니까 가장 최신 데이터만 사용하기 위해 캐시 무효화 전략(invalidation strategy)이 있어야 함

[ElastiCache Solution 아키텍처 - User Session Store]
- 사용자가 어떤 애플리케이션에 로그인하면, 애플리케이션이 세션 데이터를 아마존 ElastiCache에 쓰는 것
- 사용자가 애플리케이션의 다른 인스턴스로 리디렉션되면, 애플리케이션은 그 세션의 세션 캐시를 아마존 ElastiCache에서 직접 검색할 수 있으므로, 사용자는 다시 한 번 더 로그인할 필요가 없이 여전히 로그인된 상태임
- 즉 애플리케이션을 사용자의 세션데이터를 아마존 ElastiCache에 기록해서 stateless(상태 비저장형)으로 만드는 것

[ElastiCache - Redis VS Memcached]
- Redis
1. 자동 장애 조치 기능이 있는 Multi AZ가 있고, 읽기 복제본이 있음
2. RDS와 매우 유사하게 읽기 복제본을 scaling함
3. AOF persistence를 이용한 데이터 내구성
4. 백업 및 복원기능 있음
5. ☆Redis는 데이터 내구성에 대한 것으로 기능 면에서는 캐시로서, Sets 및 Sorted Sets를 지원함
6. Redis는 복제되는 캐시로 가용성과 내구성이 뛰어남

- Memcached
1. 데이터 분할을 위해 Multi Node를 사용(Sharding)
2. 고가용성이 없고 복제가 일어나지 않으며 영구 캐시가 아니고 백업 및 복원도 없음
3. 멀티쓰레드 아키텍처
4. Memcached에서는 여러 인스턴스가 모두 샤딩을 통해 작동
5. Memcached는 분산되어 있는 순수한 캐시로 데이터가 손실되어도 괜찮은 경우

[ElastiCache - Cache Security]
- ElastiCache는 Redis에서만 IAM 인증을 지원하며, 나머지 경우 사용자 이름과 비밀번호를 사용
- ElastiCache에서 IAM 정책을 정의하면 AWS API 수준 보안에만 사용

- Redis AUTH
1. Redis AUTH라는 Redis 내 보안을 통해 비밀번호와 토큰을 설정 가능
2. Redis 클러스터를 만들 때, 캐시에 추가 보안 수준을 제공(보안 그룹에 추가)
3. 또한 SSL 전송 중 암호화도 지원

- Memcached
1. SASL 기반 승인을 제공

- 예를 들어 EC2 인스턴스와 클라이언트가 있는 경우 Redis AUTH를 사용하여 Redis 클러스터에 연결 가능
- Redis 보안그룹에 의해 보호됨
- 또한, 전송 중 암호화를 사용하거나, Redis에서 IAM 인증을 활용할 수 있음

[ElastiCache에 데이터를 로드하는 패턴]
- Lazy Loading(지연 로딩)
1. 모든 데이터가 캐시되고 데이터가 캐시에서 지체될 수 있음
2. 캐시 히트가 없는 경우에만 데이터를 Amazon ElastiCache에 로드하기 때문에 지연 로딩이라고 불림

- Write Through
1. DB에 데이터가 기록될 때마다 캐시에 데이터를 추가하거나 업데이트하는 것
2. 데이터가 지체되지 않음

- Session Store
1. 유지 시간 기능(TTL)을 사용해 세션을 만료할 수 있음
2. 임시 세션 데이터를 캐시에 저장

[☆Elasti Cache - Redis Use Case]
- 게이밍 리더보드 만들기
- Redis에는 Sorted Sets가 있어서 고유성과 element 순서를 모두 보장
- element가 추가될 때마다, 실시간으로 순위를 매긴 다음 올바른 order로 추가
- Redis 클러스터가 있는 경우 실시간 리더보드를 만들 수 있음
- 즉 실시간으로 1~3위 플레이어를 구할 수 있음
- 모든 Redis 캐시는 동일한 리더보드 사용 가능
- 즉, 클라이언트가 Redis를 사용하여 아마존 elasticache와 Communication할 때, 이 실시간 리더보드에 엑세스할 수 있으며, 애플리케이션 측에서 이 기능을 프로그래밍할 필요가 없음
- Sorted Sets와 함께 Redis를 활용하여 실시간 리더보드에 엑세스 가능

[포트 목록]
- 중요한 포트
1. FTP: 21
2. SSH: 22
3. SFTP: 22 (SSH와 같음)
4. HTTP: 80
5. HTTPS: 443

- RDS 데이터베이스 포트
1. PostgreSQL: 5432
2. MySQL: 3306
3. Oracle RDS: 1521
4. MSSQL Server: 1433
5. MariaDB: 3306 (MySQL과 같음)
6. Aurora: 5432 (PostgreSQL와 호환될 경우) 또는 3306 (MySQL과 호환될 경우)

[DNS(Domain Name System)]
- 사람에게 친숙한 호스트 이름을 대상 서버 IP주소로 번역해줌
- 예를 들어, 웹 브라우저에 www.google.com을 입력하면 IP주소를 주고 웹 브라우저가 이면에서 여기에 접근하여 구글로부터 데이터를 얻음
- DNS는 인터넷의 중추로 URL과 호스트 이름을 IP로 변환하는 것

[DNS의 계층적 이름 구조]
- .com
- example.com
- www.example.com or api.example.com

[DNS 관련 용어]
- Domain Registrar
1. 도메인 이름을 등록하는 곳
2. 예시로는 Amazon Route 53, GoDaddy 등
3. 온라인에서 찾을 수 있는 다른 레지스트라들도 있음
- DNS Records
1. A, AAAA, CNAME, NS 등 여러 종류가 있음
- Zone File
1. 모든 DNS Record를 포함
2. 호스트 이름과 IP 또는 주소를 일치시키는 방법
- Name Server
1. DNS 쿼리를 실제로 해결하는 서버
- Top Level Domain(TLD)
1. .com, .us, .in, .gov, .org 등
- Second Level Domain(SLD)
1. amazon.com, google.com 등
- http://api.www.example.com.
1. 마지막에 있는 .은 root
2. .com은 TLD
3. example.com이 2단계 도메인
4. www.example.com이 서브 도메인
5. api.www.example.com이 도메인 이름
6. HTTP부분은 사용하기를 원하는 프로토콜
7. 이 전체를 FQDN(Fully Qualified Domain Name)이라고 함

[DNS 동작 방식]
- 웹 서버(공인 IP : 9.10.11.12)에 도메인 이름을 example.com로 하여 접근하고 싶은 상황
-  example.com이란 도메인 이름을 DNS용 서버를 등록해야 함
- 웹 브라우저가 example.com에 접근하기 위해서 로컬 DNS 서버(서브도메인의 DNS 서버 / 최종 서버 / Domain Name Registrar에 의해 관리됨 / ex. 아마존 Route 53 등)에 질의함
- 로컬 DNS 서버는 보통 회사에 의해 할당되고 관리되거나 인터넷 서비스 제공자에 동적으로 할당됨
- 로컬 DNS 서버가 이 쿼리를 전에 본 적이 없다면 먼저 ICANN에 의해 관리된 DNS 서버의 root에 질의
- root DNS 서버는 .com(Name Server 레코드 / IP : 1.2.3.4)로 응답
- 로컬 DNS 서비스는 이제 IANA(Branch of ICANN)에 의해 관리되는 TLD DNS 서버(.com 도메인 서버 / IP : 1.2.3.4)에게 쿼리의 답을 요청
- TLD DNS 서버는 example.com(Name Server 레코드 / IP : 5.6.7.8)로 응답
- 이 과정을 SLD 등등에 계층적으로 실행하여 9.10.11.12 IP를 얻음
- 이제 DNS 서버가 답을 알고 있으므로 바로 답변할 수 있음
- 따라서 답변을 웹 브라우저에 보내고 브라우저는 답변을 받아 IP 주소를 이용하여 웹 서버에 접근할 수 있음

[아마존 Route 53]
- 고가용성, 확장성을 갖췄고 완전히 관리되며 권한이 있는 DNS
- 권한은 사용자가 DNS 레코드를 업데이트할 수 있는 권한을 의미
- 즉, DNS에 대한 완전한 제어를 할 수 있음
- 클라이언트가 EC2 인스턴스(example.com)에 접근하고자 하고 EC2 인스턴스에는 public IP만 있을 때 DNS 레코드를 아마존 Route 53의 호스팅 존에 쓰려고 함
- 클라이언트가 example.com을 요청하면 Route 53 서비스가 IP 54.22.33.44를 찾고 있다고 응답
- 그러면 클라이언트는 바로 EC2 인스턴스에 접근
- Route 53 역시 도메인 네임 레지스트라로 도메인 이름을 example.com으로 등록
- 또한 Route 53의 리소스 관련 상태 확인을 할 수 있음
- 100% SLA 가용성을 제공하는 유일한 AWS 서비스
- 53은 DNS 서비스, 즉, 이름에서 사용되는 전통적인 DNS 포트

[Route 53 - Records]
- Route 53에서 여러 DNS 레코드를 정의하고 레코드를 통해 특정 도메인으로 라우팅하는 방법을 정의
- Each record Contains
1. Domain/subDomain Name : 예시) example.com
2. Record Type : 예시) A, AAAA 
3. Value : 예시) 123.456.789.123
4. Routing Policy : Route 53이 쿼리에 응답하는 방식
5. TTL(Time To Live) : DNS Resolver에서 레코드가 캐싱되는 시간
- ☆Route 53에서 반드시 알아야 하는 Record Type : A, AAAA, CNAME, NS
- 설정할 수 있는 고급 레코드 : CAA, DS, MX, NAPTR, PTR, SOA, TXT, SPF, SRV

[Route 53 - Record Types]
- A
1. hostname과 IPv4 IP를 매핑
2. 예를 들어 example.com은 1.2.3.4로 바로 연결

- AAAA
1. hostname과 IPv6 IP를 매핑

- CNAME
1. 호스트 이름을 다른 호스트 이름과 매핑
2. 대상 호스트 이름은 A나 AAAA레코드가 될 수 있음
3. Route 53에서 DNS Namespace 또는 Zone Apex의 상위 노드에 대한 CNAMES를 생성할 수 없음
4. 예를 들어 example.com에 CNAME을 만들 수 없지만 www.example.com에 대한 CNAME 레코드는 만들 수 있음

- NS
1. Hosted Zone의 Name Server
2. 서버의 DNS 이름 또는 IP 주소로 호스팅 존에 대한 DNS 쿼리에 응답할 수 있음
3. 또한, 트래픽이 도메인으로 라우팅되는 방식을 제어

[Route 53 - Hosted Zones]
- 호스팅 존은 레코드의 컨테이너
- 도메인과 서브도메인으로 가는 트래픽의 라우팅 방식을 정의

- Public Hosted Zone
1. 퍼블릭 도메인 이름을 살 때마다 mypublicdomain.com이 퍼블릭 도메인 이름이라면 퍼블릭 호스팅 존을 만들 수 있음
2. 퍼블릭 존은 쿼리에 도메인 이름 application1.mypublicdomainname.com의 IP가 무엇인지 알 수 있음
3. 공개된 클라이언트로부터 온 쿼리에 응답 가능

- Private Hosted Zone
1. 공개되지 않은 도메인 이름을 지원
2. 가상 프라이빗 클라우드(VPC)만이 URL을 Resolve할 수 있음
3. application1.company.internal와 같이 사기업에서 회사 네트워크 내에서만 접근할 수 있는 URL
4. 비공개 URL이므로 비공개되어 있고 이면에는 Private DNS 레코드가 있음

- AWS에서 만드는 어떤 호스팅 존이든 월에 50센트를 지불해야 함
- Route 53은 무료가 아니며 도메인 이름을 등록하면 일 년에 최소 12달러를 지불해야 함

[Route 53 - Records TTL (Time To Live)]
- 클라이언트가 DNS route 53과 웹 서버에 접속하는 상황
- myapp.example.com에서 DNS 요청을 보내면 DNS로부터 A 레코드와 IP주소 그리고 TTL을 회신 받음
- TTL의 설정이 300초라고 가정하면 300초 동안 TTL은 클라이언트에게 이 결과를 캐시하도록 요청
- 즉 클라이언트가 재요청을 보내거나 같은 호스트 이름으로 접속할 경우 클라이언트는 DNS 시스템에게 쿼리를 보내지 않아도 된다는 의미(이미 답변을 캐시에 저장했기 때문)
- 하지만 캐시에도 시간이 소요되니 캐시 TTL이 발생
- 레코드가 자주 바뀌지 않으므로 DNS 요청 쿼리를 계속해서 자주 보내는 상황을 원치 않음
- 그러므로 이미 저장된 답변을 이용함으로써 웹 서버에 접속이 가능하며 HTTP 요청 및 회신을 보낼 수 있음
- TTL을 24시간으로 엄청 높게 설정하면 결과가 24시간 동안 캐시가 되어 클라이언트는 요청을 적게 보내게 되므로 Route 53의 트래픽은 현저히 적어짐
- 하지만 클라이언트가 오래된 레코드를 받을 가능성이 있음
- 레코드를 바꾸고자 한다면 모든 클라이언트들이 새 레코드를 캐시에 저장할 때까지 24시간을 기다려야 한다는 뜻
- 반대로 TTL을 60초 정도로 짧게 설정한다면 Route 53에 들어오는 요청의 양에 따라 요금이 측정되므로 DNS에는 트래픽의 양이 많아져서 비용이 많이 발생 
- 하지만 오래된 레코드의 보관 시간은 짧아지고 레코드 변경이 빨라져 더욱 편리해짐
- 그러므로 어떤 TTL 설정은 더 적합할지는 상황에 따라 달라짐
- 예를 들어 TTL을 24시간으로 늦춘 다음 모든 클라이언트가 느린 새 TTL을 가지고 있다는 점을 확인한 후, 레코드 값을 바꿔서 모두에게 업데이트가 되면 TTL을 올리는 방식을 사용
- TTL은 모든 레코드에 있어서 필수적이지만 별칭 레코드는 제외

[CNAME vs Alias]
- 로드 밸런서나 CloudFront 등 AWS의 리소스를 사용하는 경우 호스트 이름이 노출
- 보유한 도메인에 호스트 이름을 매핑할 수 있음
- 예를 들어 myapp.mydomain.com에 로드밸런서를 매핑하는 경우가 있음

- CNAME
1. 호스트 이름이 다른 호스트 이름으로 향하도록 할 수 있음
2. myapp.mydomain.com이 blabla.anything.com으로 향하는 예시
3. 루트 도메인 이름이 아닌 경우에만 가능해서 mydomain.com 앞에 뭔가 붙어야 함

- ☆Alias(별칭)
1. Route 53에 한정되어 있음
2. 호스트 이름이 특정 AWS 리소스로 향하도록 할 수 있음
3. 가령 app.mydomain.com이 blabla.amazonaws.com을 향할 수 있음
4. root 및 root가 아닌 도메인 모두 작동
5. mydomain.com을 별칭으로 사용하여 AWS 리소스로 향하도록 할 수 있기 때문에 아주 유용
6. 무료이고 자체적으로 상태 확인 가능

[Route 53 - Alias Records]
- AWS의 리소스에만 매핑 가능
- 예를 들어 Route 53에서 example.com을 A 레코드의 별칭 레코드로 하고 그 값은 로드 밸런서의 DNS 이름을 지정하려 한다고 가정
- 이건 DNS의 확장 기능으로 모든 DNS에서 가능
- 만약 기반 ALB에서 IP가 바뀌면 별칭 레코드는 이걸 바로 인식
- CNAME과 달리, 별칭 레코드는 Zone Apex라는 DNS 네임스페이스의 상위 노드로 사용 가능
- example.com에도 별칭 레코드 사용 가능
- AWS 리소스를 위한 별칭 레코드의 타입은 항상 A 또는 AAAA인데 리소스는 IPv4나 IPv6중 하나
- 별칭 레코드를 사용하면 TTL을 설정할 수 없음(Route 53에 의해 자동으로 설정)

[Route 53 - Alias Records Targets]
- ELB(Elastic Load Balancer)
- ClouldFront Distributions
- API Gateway
- Elastic Beanstalk environments
- S3 웹사이트(S3 버킷은 안됨 / 버킷들이 웹사이트로 활성화될 시 S3 웹사이트 가능)
- VPC Interface Endpoints
- Global Accelerator 가속기
- 동일 호스트 존의 Route 53 레코드

- ☆EC2 DNS 이름에 대해서는 별칭 레코드 설정 불가능!!

[Route 53 - Routing Policies]
- 라우팅 정책은 Route 53이 DNS 쿼리에 응답하는 것을 도움
- 로드 밸런서가 트래픽을 백엔드 EC2 인스턴스로 라우팅하는 것과는 다른 뜻의 라우팅임
- 여기서 라우팅은 DNS 관점으로 DNS는 트래픽을 라우팅하지 않고 트래픽은 DNS를 통과하지 않음
- DNS는 DNS 쿼리에만 응답하게 되고 클라이언트들은 이를 통해 HTTP 쿼리 등을 어떻게 처리해야 하는지를 알 수 있게 됨
- DNS는 호스트 이름들을 클라이언트가 실제 사용 가능한 엔트 포인트로 변환하는 것을 도움
- Route 53이 지원하는 라우팅 정책
1. Simple : 단순
2. Weighted : 가중치 기반
3. Failover : 장애 조치
4. Latency based : 지연 시간 기반
5. Geolocation : 지리적
6. Multi-Value Answer : 다중 값 응답
7. Geoproximity(using Route 53 Traffic Flow feature) : 지리 근접 라우팅

[Routing Policies - Simple]
- 기존에 사용해 왔던 방식
- 일반적으로 트래픽을 단일 리소스로 보내는 방식
- 예를 들어 클라이언트가 foo.example.com으로 가고자 하면 Route 53이 IP 주소를 알려줌(이는 A 레코드 주소)
- 동일한 레코드에 여러 개의 값을 지정하는 것도 가능
- DNS에 의해 다중 값을 받은 경우에도 클라이언트 쪽에서 그 중 하나를 무작위로 고르게 됨
- 예를 들어 클라이언트가 foo.example.com으로 가고자 하면 Route 53이 세 개의 IP 주소(A 레코드에 임베딩된 주소)로 응답
- 그럼 클라이언트가 셋 중 하나를 골라서 라우팅에 적용
- 단순 라우팅 정책에 별칭 레코드를 함께 사용하면 하나의 AWS 리소스만을 대상으로 지정할 수 있음
- 하지만 상태 확인은 할 수 없음

[Routing Policies - Weighted]
- 가중치를 활용해 요청의 일부 비율을 특정 리소스로 보내는 식의 제어가 가능
- 예를 들어 Route 53이 있고 세 개의 EC2 인스턴스에 70, 20, 10의 가중치를 각각 할당 받은 상황
- Route 53에서 오는 DNS 응답의 70%가 첫 번째 EC2 인스턴스로 리다이렉팅된다는 의미
- 따라서, 각 레코드에 상대적으로 가중치를 할당
- 각 레코드로 보내지는 트래픽의 양 = 해당 레코드 가중치 / 전체 가중치
- 가중치의 합은 100일 필요는 없음
- 이렇게 하기 위해 DNS 레코드들은 동일한 이름과 유형을 가져야 하며 상태 확인과도 관련될 수 있음
- 가중치 기반 정책이 사용되는 경우
1. 서로 다른 지역들에 걸쳐 로드 밸런싱을 할때
2. 적은 양의 트래픽을 보내 새 애플리케이션을 테스트하는 경우에도 사용
- 가중치 0의 값을 보내게되면 특정 리소스에 트래픽 보내기를 중단해 가중치를 바꿀 수 있음
- 만약 모든 리소스 레코드 가중치의 값이 0인 경우 모든 레코드가 다시 동일한 가중치를 갖게 됨

[Routing Policies - Latency-based]
- 지연 시간이 가장 짧은, 즉 가장 가까운 리소스로 리다이렉팅을 하는 정책
- 지연 시간에 민감한 웹사이트나 애플리케이션이 있는 경우에 매우 유용
- 지연 시간은 유저가 레코드로 가장 가까운 식별된 AWS 리전에 연결되기까지 걸리는 시간을 기반으로 측정
- 만약 미국에 있는 리소스의 지연시간이 가장 짧다면, 해당 유저는 미국 리전으로 리다이렉팅 됨
- 이것도 상태 확인과 연결 가능

[Route 53 - Health Checks]
- 상태 확인은 주로 public resource에 대한 상태를 확인하는 방법
- 하지만 개인 리소스의 상태를 확인하는 방법도 존재

- 예시
1. 서로 다른 두 리전에 각 하나의 public 로드 밸런서가 있는 상황
2. 그 둘 뒤에서 애플리케이션이 작동중인 다중 지역 셋업이라고 가정(리전 레벨에서 고가용성을 원하는 상황)
3. 그리고 Route 53을 이용해 DNS 레코드를 만듬 
4. 유저가 mydomain.com과 같은 URL을 이용해 접속하면 해당 유저는 가장 가까운 로드밸런서로 연결(지연 시간 기반 레코드)
5. 만약 한 리전이 사용 불가능 상태가 되면 당연히 그곳으로는 유저를 보내고 싶지 않으므로 Route 53에서 상태 확인을 생성해야함
6. 양 인스턴스에 상태확인 생성 후 상태확인을 Route 53의 레코드와 연결 가능
7. 이는 DNS의 장애 조치를 자동화하기 위한 작업

- 세 가지의 상태 확인 가능
1. public Endpoint 모니터링(애플리케이션, 서버 or 다른 AWS 리소스)
2. 다른 상태 확인을 모니터링하는 상태확인(계산된 상태 확인)
3. CloudWatch 경보의 상태를 모니터링하는 상태 확인

[Health Checks - Monitor an Endpoint]
- 예시
1. ALB에 대한 eu-west-1의 상태 확인을 한다고 하면 AWS의 상태 확인이 전 세계로부터 옴
2. 전 세계로부터 15개 정도의 상태 확인이 옴
3. 이들은 사용자가 root를 설정한 public Endpoint로 모두 요청을 보냄
4. 200 OK 코드 또는 사용자가 정의한 코드를 받으면 리소스는 정상으로 간주
- 전 세계에서 온 15개의 상태 확인이 엔드포인트의 상태를 확인하고 임계값을 정상 혹은 비정상으로 설정
- 30초마다 정기적으로 확인할 수 있고 비용이 더 들지만 10초(빠른 상태 확인)마다 할 수 있는 등 간격 설정 가능
- HTTP, HTTPS와 TCP 등 많은 프로토콜을 지원
- 18% 이상의 상태 확인이 엔드 포인트를 정상이라고 판단하면 Route 53도 이를 정상이라고 간주 그렇지 않다면 비정상인 것으로 인식
- 상태 확인에 사용될 위치도 선택 가능
- 상태 확인은 로드 밸런서로부터 2xx나 3xx의 코드를 받아야만 통과가 됨
- 텍스트 기반 응답일 경우 상태 확인은 응답 자체에 해당 텍스트가 있는지 보기 위해 응답의 처음 5,120바이트를 확인
- 네트워크 관점에서 아주 중요한 부분으로 상태 확인 작동이 가능하려면 상태 확인이 사용자의 ALB나 엔드 포인트에 접근이 가능해야함
- 따라서 Route 53의 상태 확인 IP 주소 범위에서 들어오는 모든 요청을 허용해야 함
- 이 주소 범위는 화면의 우측 하단에 있는 URL에서 확인 가능

[Health Checks - Calculated Health Checks]
- 여러 개의 상태 확인 결과를 하나로 합쳐주는 기능
- 예시
1. Route 53을 보면 EC2 인스턴스가 세 개 있고 상태 확인을 세 개 생성 가능
2. 이들은 EC2 인스턴스를 하나씩 확인해주는 하위 상태 확인
3. 이 하위 상태 확인을 바탕으로 상위 상태 확인을 정의 가능
- 하위 상태 확인들을 모두 합치기 위한 조건은 OR, AND, NOT
- 하위 상태 확인을 256개까지 모니터링할 수 있음
- 상위 상태 확인을 통과하기 위해 몇 개의 상태 확인을 통과해야 하는지도 지정 가능
- 이를 사용하는 경우로는 상태 확인이 실패하는 일 없이 상위 상태 확인이 웹사이트를 관리 유지하도록 하는 경우

[Health Checks - Private Hosted Zones]
- 개인의 리소스를 모니터링하는 것은 어려운데 모든 Route 53의 상태 확인이 public web에 있기 때문에 VPC의 외부에 있어서 개인 엔드포인트에 접근이 불가능하기 때문(개인 VPC나 온프레미스 리소스인 경우)
- CloudWatch 지표를 만들어 CloudWatch 알람을 할당하는 식으로 위 문제 해결
- 그러면 CloudWatch 경보를 상태 확인에 할당할 수 있음
- ClouldWatch 메트릭을 이용해 개인 서브넷 안에 있는 EC2 인스턴스를 모니터링하는 것
- 그리고 메트릭이 침해되는 경우 ClouldWatch 알람이 생성되고 그 알람이 ALARM 상태가 되면 상태 확인은 자동으로 비정상이 됨
- 이렇게 하면 개인 리소스에 대한 상태 확인을 만든 것이나 다름이 없음

[Routing Policies - Failover(Active-Passive)]
- 예시
1. Route 53, 기본 EC2 인스턴스, 보조 EC2 인스턴스(재해 복구 EC2 인스턴스)가 있음
2. 이 경우에는 상태확인과 기본 레코드를 필수적으로 연결
3. 상태 확인이 비정상이면 자동으로 Route 53은 보조 EC2 인스턴스로 장애 조치하며 결과를 보내기 시작함
4. 그리고 보조 EC2 인스턴스도 상태확인을 연결할 수 있지만 기본과 보조가 각각 하나씩만 있을 수 있음
5. 클라이언트의 DNS 요청은 정상으로 생각되는 리소스를 자동으로 얻음
6. 기본 인스턴스가 정상이면 Route 53도 기본 레코드로 응답
7. 하지만 상태 확인이 비정상이면 장애 조치에 도움이 되는 두 번째 레코드의 응답을 자동으로 얻게 됨

[Routing Policies - Geolocation]
- 지연 시간 기반 라우팅 정책과 매우 다르게 사용자의 실제 위치를 기반으로 함
- 예를 들어 사용자가 특정 대륙이나 국가 혹은 더 정확하게 미국의 경우 어떤 주에 있는지 지정하는 것이며 가장 정확한 위치가 선택되어 그 IP로 라우팅되는 것
- 일치하는 위치가 없는 경우 Default 레코드를 생성해야 함
- 사용 사례로는 콘텐츠 분산을 제한하고 로드 밸런싱 등을 실행하는 웹사이트 현지화가 있음
- 이런 레코드는 상태 확인과 연결할 수 있음
- 예시
1. 독일의 유저는 독일어 버전의 앱을 포함한 IP로 접속되도록 독일의 지리 레코드로 정의
2. 프랑스의 경우 프랑스어의 버전의 앱을 가진 IP로 가야됨
3. 그 외의 다른 곳은 앱에서 영어 버전이 포함된 Default IP로 이동해야 함

[Geoproximity Routing Policy]
- 사용자와 리소스의 지리적 위치를 기반으로 트래픽을 리소스로 라우팅하도록 함
- 이 정책으로 편향값을 사용해 특정 위치 기반의 리소스로 더 많은 트래픽을 이동하는 것
- 따라서 지리적 위치를 변경하려면 편향값을 지정해야함
- 특정 리소스에 더 많은 트래픽을 보내려면 편향값을 증가시켜서 확장하면 됨(1 ~ 99)
- 리소스에 트래픽을 줄이려면 편향값을 음수로 축소시키면 됨(-99 ~ -1)
- 리소스는 AWS의 리소스로 속한 특정 리전을 지정하면 목록에서 자동으로 올바른 라우팅을 계산
- AWS 리소스가 아닌 온프레미스 데이터 센터인 경우 위도와 경도를 지정해서 AWS가 위치를 파악하도록 해야 함
- 기능을 선택하는 데 편향 활용을 위해 고급 Route 53 트래픽 플로우를 사용

[Geoproximity Routing Policy Higher bias in us-east-1]
- us-west-1의 리소스와 us-east-1의 리소스 각 리전의 편향값은 0으로 설정되어 있자면 분할선이 미국 정중앙에 생기고 분할선 왼쪽 사용자는 us-west-1로 이동 분할선 오른쪽 사용자는 us-east-1로 이동
- 즉 사용자 위치에서 가장 가까운 리소스 리전으로 이동하는 것
- us-west-1의 편향값은 0이고 us-east-1의 편향값은 50일 경우 두 리소스 사이 분할 선이 조금씩 왼쪽으로 이동
- 분할선 왼쪽 사용자는 us-west-1로 이동 분할선 오른쪽 사용자는 us-east-1로 이동
- 즉 편향으로 해당 리소스 us-east-1에 더 많은 사용자와 트래픽이 발생
- 예를 들어, 전 세계로 리소스를 설정하고 특정 리전에 더 많은 트래픽을 더 보내야한다고 하면 지리 근접 라우팅 정책을 사용해 특정 리전의 편향을 증가시킴
- 그러면 더 많은 사용자가 생기게 되고 특정 리전에 더 많은 트래픽이 발생
- ☆지리 근접 라우팅은 편향을 증가시켜 한 리전에서 다른 리전으로 트래픽을 보낼 때 유용

[Routing Policies - IP-based Routing]
- 클라이언트 IP 주소를 기반으로 라우팅을 정의
- Route 53에서 CIDR 목록을 정의(클라이언트 IP 범위)
- 그리고 CIDR에 따라 트래픽을 어느 로케이션으로 보내야 하는지 정함
- 이를 사용하면 IP를 미리 알고 있으므로 성능을 최적화할 수 있음
- 그리고 IP가 어디에서 오는지 아니까 네트워크 비용도 절감 가능
- 예를 들어 특정 인터넷 제공업체가 특정 IP 주소 셋을 사용하는 걸 안다면 특정 엔드포인트로 라우팅 가능

- 예시
1. Route 53에서 두 로케이션을 서로 다른 CIDR 블록으로 정의
2. 하나는 203으로 시작하고 다른 하나는 200으로 시작, 그러면 IP 범위도 정의됨
3. 이제 로케이션을 레코드(example.com)에 연결
4. 로케이션 1에서는 첫 번째 CIDR 블록을 1.2.3.4로 보내고, 두 번째 로케이션에서는 두 번째 CIDR 블록을 5.6.7.8로 보냄
5. 이 값들은 두 개의 EC2 인스턴스의 공용 IP를 나타냄
6. 사용자 A가 로케이션 1 CIDR 블록에 속하는 특정 IP로 들어오면 첫 번째 EC2 인스턴스인 IP 1.2.3.4로 보냄
7. 사용자 B가 두 번째 로케이션에 속하는 IP 주소로 들어오면 리디렉션되어 IP 5.6.7.8의 EC2 인스턴스에 대한 DNS 쿼리 응답을 받게 됨

[Routing Policies - Multi-Value]
- 트래픽을 다중 리소스로 라우팅할 때 사용
- 그래서 Route 53은 다중 값과 리소스를 반환
- 그리고 상태 확인과 연결하면 다중 값 정책에서 반환되는 유일한 리소스는 정상 상태 확인과 관련 있음
- 각각의 다중 값 쿼리에 최대 8개의 정상 레코드가 반환
- ELB와 유사해 보이지만 ELB를 대체할 수는 없음
- 클라이언트 측면의 로드 밸런싱임

- 예시
1. example.com에서 다중 A 레코드를 설정하고 상태 확인과 연결
2. 클라이언트에서 다중 값 쿼리를 실행하면 최대 8개의 레코드를 수신하게 되고 클라이언트는 하나를 선택
3. 하지만 최소한 상태 확인과 결합하면 반환되는 8개 레코드 중 1개 혹은 최대 8개의 레코드가 정상일 것을 알고 있음
4. 그래서 클라이언트는 안전한 쿼리를 가질 수 있음
5. 다중 값이 있는 단순 라우팅 정책은 상태 확인을 허용하지 않기 때문에 쿼리가 반환하는 리소스 중 하나는 비정상일 가능성이 있음
6. 그러므로 다중 값 라우팅 정책은 단순 라우팅 정책보다 더 강력한 레코드 유형

[Domain Registrar VS DNS Service]
- Domain Registrar
1. 도메인 이름 레지스트라를 통해 원하는 도메인 이름을 구매할 수 있음
2. 매년 비용을 지불해야 함
3. 지금까지 강의에서는 Route 53 콘솔을 통한 아마존 레지스트라 사용했지만 다른 도메인 이름 레지스트라를 이용해도 괜찮음(ex. GoDaddy, Google 도메인 등)
4. 대게 레지스트라를 통해 도메인을 등록하면 DNS 레코드 관리를 위한 DNS 서비스를 제공
5. 그래서 Amazon 호스트 이름으로 DNS 이름을 등록했다면 DNS 레코드 관리를 위한 Route 호스팅존을 가짐

- DNS service
1. 하지만 DNS 레코드로 AWS Route 53등을 사용하지 않고 아마존 레지스트라를 사용하거나 반대로 GoDaddy로 도메인을 등록해도 됨
2. example.com에서 구매하고 DNS 레코드는 아마존의 Route 53으로 관리하면 아주 완벽하게 허용되는 조합임

[GoDaddy as Registrar & Route 53 as DNS Service]
- GoDaddy에서 도메인을 등록하면 이름 서버 옵션이 생기는데 사용자 정의 이름 서버를 지정할 수 있음
- 먼저 Amazon Route 53에서 원하는 도메인의 공용 호스팅 영역을 생성하고 호스팅 영역 상세의 오른쪽 부분에서 이름 서버를 찾음
- 예시에 있는 4개의 이름 서버는 GoDaddy 웹사이트에서 변경해야 함
- 이제 GoDaddy에서 사용할 이름 서버에 관한 쿼리에 응답하면 이름 서버가 아마존 Route 53 이름 서버를 가리키고 그렇게 아마존 Route 53을 사용해서 해당 콘솔에서 직접 전체 DNS 레코드를 관리

[3rd Party Resistrar with Amazon Route 53]
- 정리하자면, 도메인을 타사 등록 대행사에서 구매해도 DNS 서비스 제공자로 Route 53을 사용 가능
- 사용하려면 Route 53에서 공용 호스팅 영역을 생성한 뒤 도메인을 구매한 타사 웹사이트에서 NS 혹은 이름 서버를 업데이트하면 Route 53 이름 서버를 가리키게 됨
- 그래서 도메인 이름 레지스트라는 모두 비슷해 보이지만 DNS 서비스는 다름
- 모든 도메인 이름 레지스트라가 일부 DNS 기능을 제공하더라도 다름

[Stateless Web App : WhatIsTheTime.com]
- WhatIsTheTime.com은 사람들에게 시간을 알려주는 사이트로 가정
- 각각의 인스턴스와 서버는 시간을 알고 있고 너무 단순한 기능이라서 DB가 필요없음
- 다운타임을 제거하기 위해 수직 및 수평적으로 확장할 필요가 있음

[WhatIsTheTime.com - 탄력적 IP 주가]
- t2.micro 인스턴스와 사용자가 있는 상황에서 사용자가 시간을 요청하면 오후 5시 30분이라고 응답
- 공용 EC2 인스턴스가 있고 무슨 일이 생기면 재시작할 수 있도록 EC2 인스턴스가 고정 IP 주소를 갖도록 하고 싶음
- 그렇기에 탄력적 IP주소와 연결

[WhatIsTheTime.com - 수직 확장]
- 애플리케이션이 점점 더 많은 트래픽을 갖게 되면서 t2.micro 인스턴스로는 충분하지 않다는 것을 깨달음
- 부하를 처리하기 위해 t2.micro 인스턴스를 조금 더 큰 것으로 교체해야 하는 상황
- 이를 수직 확장이라고 함
- 따라서 인스턴스를 중지시키고 인스턴스 유형을 m5.large 유형의 인스턴스로 교체 후 다시 시작
- 탄력적 IP를 가지고 있기 때문에 동일한 공용 IP를 가지고 되고 사람들은 여전히 애플리케이션에 접근할 수 있음
- 그러나 M5로 업그레이드하는 동안 다운타임이 발생하여 그 시간동안 애플리케이션에 접근할 수 없음

[WhatIsTheTime.com - 수평 확장]
- 애플리케이션이 이전보다 더 많은 트래픽을 갖게 되면 수평 확장을 해야됨
- 두 개의 EC2 인스턴스들(m5.large)을 추가하고 모두 탄력적 IP에 연결
- 따라서 사용자들이 인스턴스들과 communication 하기 위해 세 개의 탄력적 IP의 정확한 값을 알고 있어야 함

[WhatIsTheTime.com - Route 53]
- 사용자들은 점점 더 많은 IP를 알아야 되고 운영진은 더 많은 인프라를 관리해야 됨
- 그러므로 한 계정에서 리전마다 겨우 다섯 개만 가질 수 있는 탄력적 IP를 제거 후 Route 53을 활용
- Route 53을 설정하고 웹사이트 URL은 api.whatisthetime.com
- TTL이 한 시간인 A레코드로 설정(DNS로부터 IP 리스트를 받는다는 의미)
- 사용자들이 Route 53을 쿼리하면 EC2 인스턴스들의 IP 주소들을 얻게 되고 이는 시간에 따라 변하는데 Route 53이 업데이트를 하고 동기화를 유지하니 문제가 되지 않음
- 즉 Route 53을 통해 관리할 탄력적 IP를 제거

[WhatIsTheTime.com - 로드 밸런서]
- 상황에 따라 즉시 인스턴스를 추가하고 제거할 수 있도록 확장하고 싶어짐
- 만약 기존 사용자들이 첫 번째 m5.large 인스턴스와 communication 중이었는데 이 인스턴스를 제거
- TTL이 한 시간이므로 Route 53 쿼리를 시도하면 동일한 응답을 한 시간동안 사용하게 됨
- 따라서 해당 사용자들은 그도안 애플리케이션이 다운되었다고 생각할 가능성이 높음
- 이를 해결하기 위해 로드밸런서를 추가
- 로드 밸런서를 추가함에 따라 public 인스턴스가 더 이상 없고 private EC2 인스턴스들이 있게 됨
- 이들은 같은 가용 영역에서 실행됨(더 이상 아는 정보가 없기 때문)
- 로드 밸런서에는 상태 확인 기능이 있어서 한 인스턴스가 다운되거나 작동하지 않으면 사용자로부터 해당 인스턴스로 트래픽을 전송하지 않음
- ELB는 공개되지만 사설 EC2 인스턴스들은 뒤에 숨어 있음
- 그리고 보안 그룹 규칙을 사용하여 ELB와 private EC2 인스턴스 사이의 트래픽을 제한

[WhatIsTheTime.com - Alias record]
- 이제 WhatIsTheTime.com에 대해 사용자들이 쿼리하지만 로드 밸런서가 IP 주소를 지속적으로 바꾸기 때문에 이번에는 A 레코드가 될 수 없음
- 대신, 로드 밸런서이기 때문에 Route 53으로부터 ELB를 가리키는 별칭 레코드를 사용할 수 있음
- 여기서 DNS를 바꾸지만 사용자들은 이제 로드 밸런서에 접속
- 로드 밸런서는 EC2 인스턴스로 리디렉션하고 트래픽의 균형을 잡음
- 그리고 로드 밸런서로 인스턴스들을 추가, 제거 및 정렬할 수 있음
- 또한, 상태 확인 기능 덕분에 사용자들에게 다운타임도 없음

[WhatIsTheTime.com - 오토 스케일링 그룹]
- 그러나 수동으로 인스턴스를 추가하고 제거하는 것은 어려움
- 그러므로 오토 스케일링 그룹을 실행
- 기본적으로 오토 스케일링 그룹이 요청에 따라 확장과 축소가 가능함

[WhatIsTheTime.com - 다중 AZ]
- 지진이 발생하여 AZ 1번이 다운될 경우 애플리케이션도 완전히 다운됨
- 이러한 상황을 방지하기 위해 ELB가 필요
- 상태 확인 뿐만 아니라 다중 AZ도 추가
-  AZ 1부터 3에서 실행될 것이며 이 ELB는 세 개의 AZ가 있음
- 오토 스케일링 그룹 역시  다중 AZ에 걸쳐 있게 됨
- 이 경우 AZ 1이 다운되더라고 AZ 2와 AZ 3이 있기 때문에 사용자를 위한 트래픽을 처리할 수 있다는 장점이 있음

[WhatIsTheTime.com - 용량 예약]
- 두 개의 AZ가 있고 각각 최소 하나 이상의 인스턴스가 실행 중
- 기본적으로 애플리케이션 비용을 줄이는 작업 중 용량 예약 작업 수행
- 1년 내내 두 개의 인스턴스가 항상 실행 줄일 것이기 때문에 인스턴스를 예약함으로써 미래에 상당한 비용을 절감 가능(오토 스케일링 그룹의 용량을 최소화하기 위해)
- 새로운 인스턴스가 실행되더라고 일시적일 것이고 요청에 따른 것도 괜찮음
- 극단적으로 비용 절감을 위해 스팟 인스턴스를 사용할 수 있지만 이는 인스턴스들을 종료시키게 될 수 도 있음

[WhatIsTheTime.com - ☆시험에 알아야 될 내용]
- public IP와 private IP가 갖는 목적
- Elastic IP vs Route 53 vs Load Balancers의 장점
- Route 53 TTL로 인해 A 레코드 사용 불가하여 로드 밸런서와 별칭 레코드 사용
- EC2 인스턴스 수동 관리의 어려움 및 오토 스케일링
- 오토 스케일링은 요청이 있을 때만 확장하므로 EC2 인스턴스 양을 최적으로 유지 가능
- 재난 발생을 극복하는 다중 AZ
- 정확히 응답하는 인스턴스만 트래픽을 받도록 하기 위해 ELB 상태 확인 활성화
- EC2 인스턴스가 ELB로부터의 트래픽만 받도록 보안 그룹 규칙 설정
- 비용 절감을 위한 용량 예약

[아키텍쳐의 5가지 요소]
- 비용
1. 수직 확장
2. 부하에 따라 적절한 양의 인스턴스를 갖기 위해 ASG를 사용
3. 비용 최적화를 위해 인스턴스 예약

- 성능
1. 수직 확장
2. ELB와 오토 스케일링 그룹

- 신뢰성
1. 트래픽을 안정적으로 적절한 EC2 인스턴스에 전달하기 위해 Route 53 사용
2. ELB와 ASG에 대한 다중 AZ를 사용

- 보안
1. 로드밸런서와 인스턴스들을 확실히 연결하기 위해 보안 그룹을 사용

- 탁월한 운영
1. 매우 투박한 수동 프로세스에서 시작하여 오토스케일링 그룹 등의 기능을 갖추고 완전히 자동화되도록 개선

[Stateful Web App: MyClothes.com]
- 단순히 시간을 알려주기만 했고 이를 위해 DB 또는 외부 정보가 필요없는 무상태 형식의 웹 애플리케이션인 WhatIsTheTime.com
- 이번에는 사람들이 온라인으로 옷을 살 수 있게 하고 장바구니 기능이 있는 상태 유지 웹 애플리케이션인 MyClothes.com
- 사용자 수가 많으므로 수평 확장성을 유지하며 애플리케이션의 웹 티어를 최대한 무상태로 유지하고 싶음
- 비록 장바구니의 상태가 존재하지만 웹 애플리케이션을 최대한 쉽게 확장할 수 있어야 함
- 이는 사용자들이 웹사이트를 둘러볼 때 장바구니를 잃어버리면 안된다는 뜻
- 또한, 주소 등의 사용자 정보를 효과적으로 보관하고 어디에서나 접근할 수 있는 DB에 저장

[MyClothes.com - ELB Stickness]
- 사용자, Route 53, 다중 AZ ELB, 오토 스케일링 그룹과 세 개의 AZ가 있는 상황
- 애플리케이션이 ELB에 접근하고 ELB가 인스턴스로 보내어 장바구니 생성
- 하지만 다음 요청은 다른 인스턴스로 보내져서 장바구니가 사라짐
- 이를 해결하기 위해 고착도 즉 세션 밀접성을 도입
- ELB Stickness 활성화
- 이제 사용자가 첫 번째 인스턴스에 접속하여 장바구니에 상품을 추가
- 고착도 덕분에 그 다음 모든 요청들도 동일한 인스턴스로 감

[MyClothes.com - User Cookies]
- 만약 EC2 인스턴스가 어떤 이유로든 종료되면 장바구니를 잃어버리게 됨
- 그러므로 EC2 인스턴스가 장바구니 내용을 저장하는 대신 사용자 쪽에서 장바구니 내용을 저장하도록 하는 것
- 로드 밸런서에 접속할 때마다 '내 장바구니에는 이런 것들이 있어'라고 말하게 하는 것
- 이는 Web Cookie를 통해 이루어짐
- 어느 서버에 접속해도 사용자가 직접 EC2 인스턴스로 장바구니 내용을 보내주기 때문에 각각의 서버가 장바구니 내용을 알 수 있음
- 이제 각각의 EC2 인스턴스가 이전에 있었던 일을 알 필요가 없는 무상태를 달성

[MyClothes.com - Server Session]
- 그러나 장바구니에 상품을 추가할 수 록 점점 더 많은 데이터가 쌓이므로 HTTP 요청이 점점 무거워지는 문제가 있음
- 또한 쿠키가 해커에 의해 변경됨으로써 사용자의 장바구니가 갑자기 수정되는 보안 위험도 존재
- 따라서 이런 종류의 아키텍처에서는 EC2 인스턴스가 반드시 사용자 쿠키의 내용을 검증해야 함
- 또한 전체 쿠키의 크기는 4KB이하까지만 가능하여 쿠키 내에는 매우 작은 정보만 저장 가능
- 이러한 이유로 서버 세션을 도입
- 전체 장바구니를 웹 쿠키로 보내는 대신에 단순히 세션 ID만 보내는 것
- 이것은 사용자에 대한 세션 ID임
- 백그라운드에는 ElastiCache 클러스터가 존재
- 세션 ID를 보낼 때 EC2 인스턴스에게 '이 물건을 장바구니에 추가할거야'라고 함
- 그러면 EC2 인스턴스는 장바구니 내용을 ElastiCache에 추가하고 이 장바구니 내용을 불러올 수 있는 ID가 바로 세션 ID가 됨
- 사용자가 세션 ID와 함께 다른 EC2 인스턴스에 요청을 해도 ElastiCache로부터 장바구니 내용을 찾아서 세션 데이터를 불러올 수 있음
- ElastiCache의 또 다른 장점은 1천분의 1초 이하 성능을 가졌으므로 이 과정이 매우 빠르게 진행
- 세션 데이터 저장의 또 다른 방식으로 DynamoDB가 있음
- ElastiCache가 정보의 출처이고 해커가 ElastiCache의 내부를 수정할 수 없기 때문에 훨씬 안전해짐

[MyClothes.com - RDS(DB)]
- 사용자 데이터(사용자 주소 등)를 DB에 장기적으로 저장하고 싶을 때는 EC2 인스턴스와 RDS 인스턴스의 통신
- RDS와 통신함으로써 주소, 이름 등의 사용자 데이터를 저장하거나 불러올 수 있음
- 각각의 인스턴스가 RDS와 통신할 수 있으며 일종의 다중 AZ 무상태 솔루션을 효과적으로 얻을 수 있음
 
[MyClothes.com - Scaling Read]
- 트래픽이 늘어나고 웹사이트를 읽는 요청이 늘어날 때 읽기를 확장하고 싶음
- 쓰기를 수행하는 RDS 마스터를 사용하거나 복제가 일어나는 RDS 읽기 전용 복제본을 사용 가능
- 즉 뭔가를 읽을 때 읽기 전용 복제본으로부터 읽음
- RDS에서는 다섯 개의 읽기 전용 복제본을 가질 수 있음
- 이는 RDS DB의 읽기를 확장할 수 있도록 해줌
- 또 다른 패턴으로 캐시를 사용하는 쓰기 모드가 있음
- 사용자가 EC2 인스턴스와 통신하는 방식으로 작동하며 캐시를 살펴보고 "이런 정보가 있나요?'라고 물어봄
- 가지고 있지 않다면 RDS로부터 읽어 들여서 ElastiCache에 집어넣는 캐싱 동작 수행
- 단 다음에는 ElastiCache와 통신할 때는 캐시 히트이므로 즉시 응답을 받음
- 이 패턴을 통해 RDS상의 트래픽을 줄일 수 있음
- 기본적으로 RDS상의 CPU 사용을 줄이고 동시에 성능을 향상시키는 것
- 그러나 캐시 유지보수가 필요함

[MyClothes.com - Survive disaster]
- 재해로 인해 피해를 받지 않으려면 가용성을 높여야 됨
- 그러나 Route 53은 이미 가용성이 높음
- 그러므로 로드 밸런서를 다중 AZ로 만듬
- 오토 스케일링 그룹도 다중 AZ
- RDS 역시 다중 AZ 기능이 있음
- 또 다른 방법으로 재해가 발생할 경우 인계받을 수 있는 대기 복제본이 있음
- Redis를 사용한다면 ElastiCache도 다중 AZ 기능을 가지고 있음
- 이제 전반적으로 다중 AZ 애플리케이션이 됨

[MyClothes.com - Security Groups]
- ELB 쪽 어디에서나 HTTP HTTPS 트래픽을 열 수 있음
- EC2 인스턴스 측면에서는 로드밸런서로부터 오는 트래픽만 제한
- ElastiCache 측면에서는 EC2 보안 그룹으로부터 오는 트래픽만 제한
- RDS도 마찬가지로 EC2 보안 그룹으로부터 오는 트래픽을 제한

[MyClothes.com - 웹 애플리케이션 아키텍처]
- ELB 고정 세션
- 쿠키 저장을 위한 웹 클라이언트(Web app 무상태)
- ElastiCache
1. 세션 ID와 세션 캐시의 사용(대안 : DynamoDB)
2. 읽기의 경우 RDS로부터 데이터를 캐싱하는 ElastiCache
3. 재해에 대비하기 위한 다중 AZ
- RDS
1. 사용자 데이터를 저장하기 위해 더 오래가는 데이터 형식 RDS
2. 읽기 전용 복제본은 읽기 확장에 사용하고 또는 ElastiCache를 사용
3. 재해 복구를 위한 다중 AZ
- 서로 참조하는 보안 그룹을 통한 철저한 보안
- 클라이언트 티어, 웹 티어, DB 티어 총 3개의 티어는 매우 보편적인 아키텍처
- 비용은 증가하지만 아키텍처 관련 결정을 내릴 떄 도움이 되는 것들을 얻을 수 있음

[Stateful Web App: MyWordPress.com]
- 완전히 확장 가능한 WordPress 웹사이트를 만들고자 함
- WordPress는 웹사이트를 만드는데 흔히 사용되는 방법
- 업로드한 그림이 바르게 나타나길 원함
- WordPress가 작동하는 방식으로 어떤 드라이브에 그림을 저장하고 기본적으로 모든 인스턴스들이 그 데이터에 접근해야함
- 사용자 데이터와 블로그 내용 등 모든 것이 MySQL DB에 저장되야 되고 글로벌하게 확장하고 싶은 상황

[MyWordPress.com - RDS]
- 백엔드에 RDS가 있는 아키텍처
- 다중 AZ이고 모든 EC2 인스턴스에 걸쳐 적용

[MyWordPress.com - 오로라 MySQL]
- 정말로 크게 확장하고 싶으면 RDS 계층을 오로라 MySQL로 교체
- 다중 AZ, 읽기 전용 복제본, 글로벌 DB까지 적용 가능
- 오로라를 사용함으로써 연산을 줄일 수 있음
- 오로라는 확장성있고 기록하기 쉬움

[MyWordPress.com - EBS]
- 하나의 EC2 인스턴스와 하나의 EBS 볼륨이 연결되어 있는 단일 AZ에 로드 밸런서가 연결되어 있음
- 사용자는 로드 밸런서로 이미지를 보내고 싶음
- 그 이미지는 EBS에 도달하여 EBS에 저장됨
- EC2 인스턴스가 하나일 때는 잘 동작하지만 두 개의 EC2 인스턴스와 두 개의 AZ 그리고 각각의 EC2 인스턴스는 EBS 볼륨을 가지고 있는 상황
- 첫번째 EC2 인스턴스에 접근해서 EBS에 이미지를 저장했는데 그 다음 두번째 EC2 인스턴스에 접근했을 때는 그 인스턴스의 EBS에는 해당 이미지가 없으므로 접근할 수 없음
- EBS 볼륨의 단점은 하나의 인스턴스만 있을 때는 잘 동작하지만 다중 AZ 또는 다중 인스턴스로 확장 시 문제 발생

[MyWordPress.com - EFS]
- 위와 같은 상황을 해결하기 위해 EFS 즉 NFS(Network File System) 드라이브 사용
- EFS는 탄력적인 네트워크 인터페이스를 위해 각각의 AZ에 ENI를 생성
- 이 ENI는 EFS 드라이브에 접근하는 모든 EC2에 사용 가능
- 스토리지가 모든 인스턴스에게 공유가 됨
- 즉 EC2 인스턴스로 이미지를 보내면 ENI를 거쳐 EFS로 전달되고 이미지가 EFS에 저장
- 다른 EC2 인스턴스에 접근해서 그 이미지를 불러오고 싶으면 ENI를 거쳐 EFS로부터 읽어들임
- AZ나 인스턴스 숫자에 관계없이 모든 인스턴스가 동일한 파일에 접근하도록 허용하기 위해 다수의 EC2 인스턴스를 걸쳐 웹사이트 스토리지를 확장하는 아주 흔한 방법

[MyWordPress.com - 정리]
- 적은 연산량과 다중 AZ 및 읽기 전용 복제본을 갖춘 오로라 DB
- EBS와 EFS 차이
1. 단일 인스턴스 애플리케이션에서 아주 잘 동작하는 EBS에 데이터 저장
2. 인스턴스가 많아지게 될 시 EFS를 사용하여 다중 AZ에 걸친 분산 애플리케이션을 생성 가능
3. 비용 관점에서 볼 때 EBS가 EFS보다 싸지만 EFS를 사용할 때 많은 이점을 얻을 수 있음
- 즉, 작업에 대한 장단점과 왜 그 작업을 하는지 그리고 그로 인한 비용을 이해하는 방식으로 공부 진행

[Instantiating Applications quickly]
- 풀 스택(EC2, EBS, RDS)을 실행하면 아래 과정을 수행하는 데 매우 긴 시간이 걸림
1. 애플리케이션 설치
2. 데이터 삽입 및 복구
3. 모든 내용 구성
4. 애플리케이션 실행
- 속도를 높이기 위해 클라우드 장점 사용

[Instantiating Applications quickly - Golden AMI]
- Golden AMI는 애플리케이션과 OS 종속성 등 모든 것을 사전에 설치하고 그것으로부터 AMI를 생성
- 이후로는 EC2 인스턴스들을 Golden AMI로부터 직접 실행
- 이렇게 하는 이유는 애플리케이션, OS 종속성 등을 재설치할 필요가 없기 때문
- 모든 것이 이미 설치된 상태에서 바로 실행 가능
- 이것이 EC2 인스턴스를 시작하는 가장 빠른 방법이자 클라우드에서 아주 흔한 패턴

[Instantiating Applications quickly - Bootstrap]
- User 데이터를 사용하여 부트스트래핑
- 부트스트래핑은 기본적으로 인스턴스가 처음 시작될 때 구성하는 것을 의미
- 즉 애플리케이션, OS 종속성 등을 설치하기 위해 부트스트래핑을 할 수 있음
- 그러나 매우 느림
- EC2 인스턴스가 다른 인스턴스가 이미 했던 완전히 같은 일을 반복하기 원하지 않음
- 예를 들어 DB URL과 비밀번호 등을 가져올 때 EC2 사용자 데이터를 사용하여 부트스트래핑을 활용할 수 있음

[Instantiating Applications quickly - Elastic Beanstalk]
- 기본적으로 Elastic Beanstalk를 통해 Golden AMI와 EC2 User 데이터를 하이브리드 혼합체로 작동하도록 할 수 있음
- Elastic Beanstalk은 AMI를 구성하고 사용자 데이터를 추가하는 하이브리드와 동일한 원칙을 적용
- RDS DB는 스냅샷으로부터 복구할 수 있고 그러면 DB에서 스키마와 데이터가 준비됨
- 이는 RDS DB를 시작하기까지 매우 긴 시간이 걸리는 대형 삽입 문장을 사용하는 것보다 훨씬 나음
- 데이터를 검색하려고 할 때 더 빠르게 할 수 있는 방법
- 스냅샷으로부터 EBS 볼륨을 복구할 수 있어서 형성되지 않은 빈 디스크는 필요하지 않음
- 스냅샷에서 가져올 수 있고 스냅샷은 이미 적절히 형성되어 있으며 필요한 데이터를 가지고 있음
- ☆EC2 인스턴스의 시작 속도를 높여야 하고 RDS DB 또는 EBS 볼륨의 속도를 높여야 하며 이 모든 것들을 형성해야됨
- ☆이것이 Golden AMI 사용자 데이터 DB 스냅샷 / EBS 스냅샷을 사용할 때 해야할 일

[Elastic Beanstalk의 필요성]
- 지금까지 배포한 애플리케이션은 모두 동일한 구조였음
1. 사용자의 모든 요청을 받는 로드밸런서
2. 다수의 AZ와 오토스케일링 그룹이 있고 각각의 AZ에 EC2 인스턴스들이 배포됨
3. 백엔드에는 데이터 서브넷, RDS DB, 읽기 레플리카 등등 있음
4. 캐싱 레이어가 필요하면 ElastiCache를 사용
- 배포할 애플리케이션이 많고 그것들이 동일한 아키텍처를 따른다면 그것을 매번 다시 생성하기 힘듬
- 개발자로서 인프라를 관리하고 코드를 배포하기가 어려워지고 DB나 로드밸런서 등등을 설정하는 게 아주 번거로움
- 그리고 개발자는 모든 걸 스케일링 하길 원함
- 또한, 개발자는 이러한 것들을 신경쓰지 않고 코드를 실행하길 원함
- 또 다른 프로그래밍 언어로 개발하고 다양한 애플리케이션 환경을 가지고 있어도 한 가지 방법으로 애플리케이션을 배포하기 원함
- 이러한 상황에서 Elastic Beanstalk를 사용

[Elastic Beanstalk]
- Beanstalk는 개발자 입장에서 애플리케이션을 AWS에 배포
- 하나의 인터페이스에서 EC2, ASG, ELB, RDS 등 모든 컴포넌트를 재사용한다는 개념
- Beanstalk가 개발자를 대신해서 모든 걸 배포하는 관리형 서비스
- 즉 Beanstalk가 용량 프로비저닝, 로드 밸런서 설정, 스케일링, 애플리케이션 상태 모니터링, 인스턴스 설정 등을 처리
- 그러면 개발자는 코드 자체만 담당하면 됨
- 그래도 개발자는 모든 컴포넌트 설정에 대한 컨트롤를 갖게 됨, 적어도 그것들이 Beanstalk에서 하나의 인터페이스 번들로서 제공
- Beanstalk 서비스 자체는 무료이며 Beanstalk가 활용하는 인스턴스나 ASG, ELB 등에 대해 비용을 지불하게 됨

[Elastic Beanstalk 구성]
- Beanstalk 컴포넌트는 환경, 버전, 설정 등 Beanstalk 컴포넌트 Collection인 애플리케이션으로 구성
- 애플리케이션 자체의 버전은 개발자의 애플리케이션과 같게 됨
- 환경은 특정한 애플리케이션 버전을 실행하는 리소스들의 Collection
- 개발자는 어떤 환경에서 한번에 하나의 애플리케이션 버전만 가질 수 있음
- 하지만 어떤 환경에서 애플리케이션 버전을 버전 1에서 버전 2로 업데이트할 수 있음
- Beanstalk에는 웹 서버 환경 티어, 워커 환경 티어 두 개의 티어가 있음
- Beanstalk에서 dev, test, prod같은 다양한 환경을 만들 수 있음
- Beanstalk 프로세스
1. 먼저 애플리케이션 생성
2. 버전을 업로드하고 
3. 환경을 설정함
4. 환경 라이프사이클 관리
5. 이를 반복하고 싶으면 새 버전을 업로드해서 버전을 업데이트하고 환경에서 새 버전을 배포해서 애플리케이션 스택을 업데이트 할 수 있음

[Elastic Beanstalk - Supported Platform]
- Beanstalk의 언어지원
1. Go
2. Java SE
3. Java with Tomcat
4. .NET Core on Linux
5. .NET on Windows Server
6. Node.js
7. PHP
8. Python 
9. Ruby 
10. Packer Builder 
11. Single Docker Container
12. Multi-Docker Container, 
13. Preconfigured Docker
- 이외에도 커스텀 플랫폼이라는 고급 기능을 통해 지원되지 않는 언어에 대한 플랫폼을 생성 가능
- 즉 Beanstalk에서 사실상 모든걸 배포할 수 있음

[Elastic Beanstalk - Web Server Tier VS Worker Tier]
- 웹 서버 티어
1. 로드밸런서가 트래픽을 오토 스케일링 그룹에 전송 
2. 거기에 개발자의 웹 서버가 될 다수의 EC2 인스턴스가 있는 전통적인 아키텍처

- 워커 티어
1. 환경을 중심으로 이루어져 있음
2. 즉 EC2 인스턴스에 직접적으로 엑세스하는 클라이언트가 없음
3. 개발자는 메시지 대기열인 SQS Queue를 사용
4. 메시지는 SQS Queue로 전송되고 EC2 인스턴스는 워커가 됨
5. 왜냐하면 그것들이 메시지를 SQS Queue에서 가져와서 처리하기 때문
6. 이 경우에 워커 환경은 SQS 메시지의 개수에 따라 스케일링 됨

- 웹 환경이 메시지를 워커 환경의 SQS Queue에 푸시하게 함으로써 웹 환경과 워쿼 환경을 하나로 모을 수 있음

[Elastic Beanstalk Deployment Modes]
- Beanstalk는 싱글 인스턴스와 로드 밸런서를 사용하는 고가용성 두 가지 배포 모드가 존재

- 싱글 인스턴스
1. 개발용으로 좋음
2. 개발자는 탄력적 IP을 가진 하나의 EC2 인스턴스를 가짐
3. RDS DB 등을 Launch 할 수 있는데 모두 탄력적 IP를 가진 하나의 인스턴스를 기반으로 함

- 로드 밸런서를 사용하는 고가용성
1. 실제 Elastic Beanstalk 모드로 스케일링할 때 좋음
2. Production 환경에 적합
3. 로드 밸런서가 있어 로드를 다수의 EC2 인스턴스에 걸쳐 분산시킬 수 있음
4. 그것들이 오토 스케일링 그룹과 다수의 AZ에 맞춰 관리
5. 멀티 AZ이며 마스터와 스탠바이가 있는 RDS DB를 가질 수 있음
